{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjr5fQJSHI-b"
      },
      "source": [
        "# Imports\n",
        "## Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_g5ppEMUUOZn"
      },
      "outputs": [],
      "source": [
        "!pip install transformers==4.10.0 &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXiuOWqVYmaa",
        "outputId": "ed33ce36-2103-48ba-b495-b402044f3bfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 16.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.0)\n",
            "Collecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.7 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.1+cu113\n",
            "    Uninstalling torch-1.12.1+cu113:\n",
            "      Successfully uninstalled torch-1.12.1+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.13.1\n",
            "    Uninstalling torchtext-0.13.1:\n",
            "      Successfully uninstalled torchtext-0.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.1+cu113 requires torch==1.12.1, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.10.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIfc330xr5yr"
      },
      "outputs": [],
      "source": [
        "from transformers import RobertaModel, RobertaTokenizer, EncoderDecoderModel, get_linear_schedule_with_warmup\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.legacy.data import BucketIterator\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torch.optim import Adam\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import json\n",
        "import ast\n",
        "import re\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XS6v8pNqHNQK"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BNOqhQsYVxh9",
        "outputId": "e4f6c8df-7a14-46b6-89b1-f8bc268011dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Require customization! This is to load the datasets from cloud storage.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EbwjVerrHOq7"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoRnZ_J2HQdL"
      },
      "source": [
        "## Create Inputs and Outputs raw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPGb70tluGP9"
      },
      "outputs": [],
      "source": [
        "with open(\"drive/MyDrive/codenet_data/train/python_train_0.jsonl\") as f:\n",
        "    jsonl_content = f.readlines()\n",
        "\n",
        "train_jsons = [json.loads(json_line) for json_line in jsonl_content]\n",
        "\n",
        "\n",
        "with open(\"drive/MyDrive/codenet_data/valid/python_valid_0.jsonl\") as f:\n",
        "    jsonl_content = f.readlines()\n",
        "#divide valid size by 10\n",
        "jsonl_content = jsonl_content[:int(len(jsonl_content)/10)]\n",
        "val_jsons = [json.loads(json_line) for json_line in jsonl_content]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqMrHR_-vT1a"
      },
      "outputs": [],
      "source": [
        "def get_func_and_name(data):\n",
        "    try:\n",
        "        node = ast.parse(data).body[0]\n",
        "        function_name = node.name\n",
        "        function = data\n",
        "        docstring = ast.get_docstring(node)\n",
        "        #remove docstring\n",
        "        if docstring is not None:\n",
        "            function = re.sub(r'\\\"\\\"\\\"(.*)\\\"\\\"\\\"',\"\",function,count=1,flags=re.DOTALL)\n",
        "        #remove function name\n",
        "        function = re.sub(function_name,\"<mask>\",function,count=1)\n",
        "        return function,function_name\n",
        "    except:\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "by4yWVBy0R6i"
      },
      "outputs": [],
      "source": [
        "training_pairs_raw = [get_func_and_name(line[\"code\"]) for line in train_jsons if get_func_and_name(line[\"code\"]) is not None]\n",
        "\n",
        "training_inputs_raw = [x for (x,y) in training_pairs_raw]\n",
        "training_labels_raw = [y for (x,y) in training_pairs_raw]\n",
        "\n",
        "val_pairs_raw = [get_func_and_name(line[\"code\"]) for line in val_jsons if get_func_and_name(line[\"code\"]) is not None]\n",
        "\n",
        "val_inputs_raw = [x for (x,y) in val_pairs_raw]\n",
        "val_labels_raw = [y for (x,y) in val_pairs_raw]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-nWCVFWaJ7m",
        "outputId": "69ab033f-15f0-4994-f26f-d1c3e64d946e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['def <mask>(env,\\n          network,\\n          seed=None,\\n          lr=5e-4,\\n          total_timesteps=100000,\\n          buffer_size=50000,\\n          exploration_fraction=0.1,\\n          exploration_final_eps=0.02,\\n          train_freq=1,\\n          batch_size=32,\\n          print_freq=100,\\n          checkpoint_freq=10000,\\n          checkpoint_path=None,\\n          learning_starts=1000,\\n          gamma=1.0,\\n          target_network_update_freq=500,\\n          prioritized_replay=False,\\n          prioritized_replay_alpha=0.6,\\n          prioritized_replay_beta0=0.4,\\n          prioritized_replay_beta_iters=None,\\n          prioritized_replay_eps=1e-6,\\n          param_noise=False,\\n          callback=None,\\n          load_path=None,\\n          **network_kwargs\\n            ):\\n    \\n    # Create all the functions necessary to train the model\\n\\n    sess = get_session()\\n    set_global_seeds(seed)\\n\\n    q_func = build_q_func(network, **network_kwargs)\\n\\n    # capture the shape outside the closure so that the env object is not serialized\\n    # by cloudpickle when serializing make_obs_ph\\n\\n    observation_space = env.observation_space\\n    def make_obs_ph(name):\\n        return ObservationInput(observation_space, name=name)\\n\\n    act, train, update_target, debug = deepq.build_train(\\n        make_obs_ph=make_obs_ph,\\n        q_func=q_func,\\n        num_actions=env.action_space.n,\\n        optimizer=tf.train.AdamOptimizer(learning_rate=lr),\\n        gamma=gamma,\\n        grad_norm_clipping=10,\\n        param_noise=param_noise\\n    )\\n\\n    act_params = {\\n        \\'make_obs_ph\\': make_obs_ph,\\n        \\'q_func\\': q_func,\\n        \\'num_actions\\': env.action_space.n,\\n    }\\n\\n    act = ActWrapper(act, act_params)\\n\\n    # Create the replay buffer\\n    if prioritized_replay:\\n        replay_buffer = PrioritizedReplayBuffer(buffer_size, alpha=prioritized_replay_alpha)\\n        if prioritized_replay_beta_iters is None:\\n            prioritized_replay_beta_iters = total_timesteps\\n        beta_schedule = LinearSchedule(prioritized_replay_beta_iters,\\n                                       initial_p=prioritized_replay_beta0,\\n                                       final_p=1.0)\\n    else:\\n        replay_buffer = ReplayBuffer(buffer_size)\\n        beta_schedule = None\\n    # Create the schedule for exploration starting from 1.\\n    exploration = LinearSchedule(schedule_timesteps=int(exploration_fraction * total_timesteps),\\n                                 initial_p=1.0,\\n                                 final_p=exploration_final_eps)\\n\\n    # Initialize the parameters and copy them to the target network.\\n    U.initialize()\\n    update_target()\\n\\n    episode_rewards = [0.0]\\n    saved_mean_reward = None\\n    obs = env.reset()\\n    reset = True\\n\\n    with tempfile.TemporaryDirectory() as td:\\n        td = checkpoint_path or td\\n\\n        model_file = os.path.join(td, \"model\")\\n        model_saved = False\\n\\n        if tf.train.latest_checkpoint(td) is not None:\\n            load_variables(model_file)\\n            logger.log(\\'Loaded model from {}\\'.format(model_file))\\n            model_saved = True\\n        elif load_path is not None:\\n            load_variables(load_path)\\n            logger.log(\\'Loaded model from {}\\'.format(load_path))\\n\\n\\n        for t in range(total_timesteps):\\n            if callback is not None:\\n                if callback(locals(), globals()):\\n                    break\\n            # Take action and update exploration to the newest value\\n            kwargs = {}\\n            if not param_noise:\\n                update_eps = exploration.value(t)\\n                update_param_noise_threshold = 0.\\n            else:\\n                update_eps = 0.\\n                # Compute the threshold such that the KL divergence between perturbed and non-perturbed\\n                # policy is comparable to eps-greedy exploration with eps = exploration.value(t).\\n                # See Appendix C.1 in Parameter Space Noise for Exploration, Plappert et al., 2017\\n                # for detailed explanation.\\n                update_param_noise_threshold = -np.log(1. - exploration.value(t) + exploration.value(t) / float(env.action_space.n))\\n                kwargs[\\'reset\\'] = reset\\n                kwargs[\\'update_param_noise_threshold\\'] = update_param_noise_threshold\\n                kwargs[\\'update_param_noise_scale\\'] = True\\n            action = act(np.array(obs)[None], update_eps=update_eps, **kwargs)[0]\\n            env_action = action\\n            reset = False\\n            new_obs, rew, done, _ = env.step(env_action)\\n            # Store transition in the replay buffer.\\n            replay_buffer.add(obs, action, rew, new_obs, float(done))\\n            obs = new_obs\\n\\n            episode_rewards[-1] += rew\\n            if done:\\n                obs = env.reset()\\n                episode_rewards.append(0.0)\\n                reset = True\\n\\n            if t > learning_starts and t % train_freq == 0:\\n                # Minimize the error in Bellman\\'s equation on a batch sampled from replay buffer.\\n                if prioritized_replay:\\n                    experience = replay_buffer.sample(batch_size, beta=beta_schedule.value(t))\\n                    (obses_t, actions, rewards, obses_tp1, dones, weights, batch_idxes) = experience\\n                else:\\n                    obses_t, actions, rewards, obses_tp1, dones = replay_buffer.sample(batch_size)\\n                    weights, batch_idxes = np.ones_like(rewards), None\\n                td_errors = train(obses_t, actions, rewards, obses_tp1, dones, weights)\\n                if prioritized_replay:\\n                    new_priorities = np.abs(td_errors) + prioritized_replay_eps\\n                    replay_buffer.update_priorities(batch_idxes, new_priorities)\\n\\n            if t > learning_starts and t % target_network_update_freq == 0:\\n                # Update target network periodically.\\n                update_target()\\n\\n            mean_100ep_reward = round(np.mean(episode_rewards[-101:-1]), 1)\\n            num_episodes = len(episode_rewards)\\n            if done and print_freq is not None and len(episode_rewards) % print_freq == 0:\\n                logger.record_tabular(\"steps\", t)\\n                logger.record_tabular(\"episodes\", num_episodes)\\n                logger.record_tabular(\"mean 100 episode reward\", mean_100ep_reward)\\n                logger.record_tabular(\"% time spent exploring\", int(100 * exploration.value(t)))\\n                logger.dump_tabular()\\n\\n            if (checkpoint_freq is not None and t > learning_starts and\\n                    num_episodes > 100 and t % checkpoint_freq == 0):\\n                if saved_mean_reward is None or mean_100ep_reward > saved_mean_reward:\\n                    if print_freq is not None:\\n                        logger.log(\"Saving model due to mean reward increase: {} -> {}\".format(\\n                                   saved_mean_reward, mean_100ep_reward))\\n                    save_variables(model_file)\\n                    model_saved = True\\n                    saved_mean_reward = mean_100ep_reward\\n        if model_saved:\\n            if print_freq is not None:\\n                logger.log(\"Restored model with mean reward: {}\".format(saved_mean_reward))\\n            load_variables(model_file)\\n\\n    return act', 'def <mask>(self, path=None):\\n        \\n        if path is None:\\n            path = os.path.join(logger.get_dir(), \"model.pkl\")\\n\\n        with tempfile.TemporaryDirectory() as td:\\n            save_variables(os.path.join(td, \"model\"))\\n            arc_name = os.path.join(td, \"packed.zip\")\\n            with zipfile.ZipFile(arc_name, \\'w\\') as zipf:\\n                for root, dirs, files in os.walk(td):\\n                    for fname in files:\\n                        file_path = os.path.join(root, fname)\\n                        if file_path != arc_name:\\n                            zipf.write(file_path, os.path.relpath(file_path, td))\\n            with open(arc_name, \"rb\") as f:\\n                model_data = f.read()\\n        with open(path, \"wb\") as f:\\n            cloudpickle.dump((model_data, self._act_params), f)', \"def <mask>(unscaled_images, **conv_kwargs):\\n    \\n    scaled_images = tf.cast(unscaled_images, tf.float32) / 255.\\n    activ = tf.nn.relu\\n    h = activ(conv(scaled_images, 'c1', nf=32, rf=8, stride=4, init_scale=np.sqrt(2),\\n                   **conv_kwargs))\\n    h2 = activ(conv(h, 'c2', nf=64, rf=4, stride=2, init_scale=np.sqrt(2), **conv_kwargs))\\n    h3 = activ(conv(h2, 'c3', nf=64, rf=3, stride=1, init_scale=np.sqrt(2), **conv_kwargs))\\n    h3 = conv_to_fc(h3)\\n    return activ(fc(h3, 'fc1', nh=512, init_scale=np.sqrt(2)))\", \"def <mask>(num_layers=2, num_hidden=64, activation=tf.tanh, layer_norm=False):\\n    \\n    def network_fn(X):\\n        h = tf.layers.flatten(X)\\n        for i in range(num_layers):\\n            h = fc(h, 'mlp_fc{}'.format(i), nh=num_hidden, init_scale=np.sqrt(2))\\n            if layer_norm:\\n                h = tf.contrib.layers.layer_norm(h, center=True, scale=True)\\n            h = activation(h)\\n\\n        return h\\n\\n    return network_fn\", \"def <mask>(nlstm=128, layer_norm=False):\\n    \\n\\n    def network_fn(X, nenv=1):\\n        nbatch = X.shape[0]\\n        nsteps = nbatch // nenv\\n\\n        h = tf.layers.flatten(X)\\n\\n        M = tf.placeholder(tf.float32, [nbatch]) #mask (done t-1)\\n        S = tf.placeholder(tf.float32, [nenv, 2*nlstm]) #states\\n\\n        xs = batch_to_seq(h, nenv, nsteps)\\n        ms = batch_to_seq(M, nenv, nsteps)\\n\\n        if layer_norm:\\n            h5, snew = utils.lnlstm(xs, ms, S, scope='lnlstm', nh=nlstm)\\n        else:\\n            h5, snew = utils.lstm(xs, ms, S, scope='lstm', nh=nlstm)\\n\\n        h = seq_to_batch(h5)\\n        initial_state = np.zeros(S.shape.as_list(), dtype=float)\\n\\n        return h, {'S':S, 'M':M, 'state':snew, 'initial_state':initial_state}\\n\\n    return network_fn\", 'def <mask>(convs=[(32, 8, 4), (64, 4, 2), (64, 3, 1)], **conv_kwargs):\\n    \\'\\'\\'\\n    convolutions-only net\\n\\n    Parameters:\\n    ----------\\n\\n    conv:       list of triples (filter_number, filter_size, stride) specifying parameters for each layer.\\n\\n    Returns:\\n\\n    function that takes tensorflow tensor as input and returns the output of the last convolutional layer\\n\\n    \\'\\'\\'\\n\\n    def network_fn(X):\\n        out = tf.cast(X, tf.float32) / 255.\\n        with tf.variable_scope(\"convnet\"):\\n            for num_outputs, kernel_size, stride in convs:\\n                out = layers.convolution2d(out,\\n                                           num_outputs=num_outputs,\\n                                           kernel_size=kernel_size,\\n                                           stride=stride,\\n                                           activation_fn=tf.nn.relu,\\n                                           **conv_kwargs)\\n\\n        return out\\n    return network_fn', \"def <mask>(name):\\n    \\n    if callable(name):\\n        return name\\n    elif name in mapping:\\n        return mapping[name]\\n    else:\\n        raise ValueError('Unknown network type: {}'.format(name))\", 'def <mask>(hiddens=[], layer_norm=False):\\n    \\n    return lambda *args, **kwargs: _mlp(hiddens, layer_norm=layer_norm, *args, **kwargs)', 'def <mask>(convs, hiddens, dueling=False, layer_norm=False):\\n    \\n\\n    return lambda *args, **kwargs: _cnn_to_mlp(convs, hiddens, dueling, layer_norm=layer_norm, *args, **kwargs)', 'def <mask>(env_id, env_type, num_env, seed,\\n                 wrapper_kwargs=None,\\n                 start_index=0,\\n                 reward_scale=1.0,\\n                 flatten_dict_observations=True,\\n                 gamestate=None):\\n    \\n    wrapper_kwargs = wrapper_kwargs or {}\\n    mpi_rank = MPI.COMM_WORLD.Get_rank() if MPI else 0\\n    seed = seed + 10000 * mpi_rank if seed is not None else None\\n    logger_dir = logger.get_dir()\\n    def make_thunk(rank):\\n        return lambda: make_env(\\n            env_id=env_id,\\n            env_type=env_type,\\n            mpi_rank=mpi_rank,\\n            subrank=rank,\\n            seed=seed,\\n            reward_scale=reward_scale,\\n            gamestate=gamestate,\\n            flatten_dict_observations=flatten_dict_observations,\\n            wrapper_kwargs=wrapper_kwargs,\\n            logger_dir=logger_dir\\n        )\\n\\n    set_global_seeds(seed)\\n    if num_env > 1:\\n        return SubprocVecEnv([make_thunk(i + start_index) for i in range(num_env)])\\n    else:\\n        return DummyVecEnv([make_thunk(start_index)])']\n",
            "['learn', 'save_act', 'nature_cnn', 'mlp', 'lstm', 'conv_only', 'get_network_builder', 'mlp', 'cnn_to_mlp', 'make_vec_env']\n",
            "['def <mask>(train_dir, model_save_path=None, n_neighbors=None, knn_algo=\\'ball_tree\\', verbose=False):\\n    \\n    X = []\\n    y = []\\n\\n    # Loop through each person in the training set\\n    for class_dir in os.listdir(train_dir):\\n        if not os.path.isdir(os.path.join(train_dir, class_dir)):\\n            continue\\n\\n        # Loop through each training image for the current person\\n        for img_path in image_files_in_folder(os.path.join(train_dir, class_dir)):\\n            image = face_recognition.load_image_file(img_path)\\n            face_bounding_boxes = face_recognition.face_locations(image)\\n\\n            if len(face_bounding_boxes) != 1:\\n                # If there are no people (or too many people) in a training image, skip the image.\\n                if verbose:\\n                    print(\"Image {} not suitable for training: {}\".format(img_path, \"Didn\\'t find a face\" if len(face_bounding_boxes) < 1 else \"Found more than one face\"))\\n            else:\\n                # Add face encoding for current image to the training set\\n                X.append(face_recognition.face_encodings(image, known_face_locations=face_bounding_boxes)[0])\\n                y.append(class_dir)\\n\\n    # Determine how many neighbors to use for weighting in the KNN classifier\\n    if n_neighbors is None:\\n        n_neighbors = int(round(math.sqrt(len(X))))\\n        if verbose:\\n            print(\"Chose n_neighbors automatically:\", n_neighbors)\\n\\n    # Create and train the KNN classifier\\n    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=n_neighbors, algorithm=knn_algo, weights=\\'distance\\')\\n    knn_clf.fit(X, y)\\n\\n    # Save the trained KNN classifier\\n    if model_save_path is not None:\\n        with open(model_save_path, \\'wb\\') as f:\\n            pickle.dump(knn_clf, f)\\n\\n    return knn_clf', 'def <mask>(X_img_path, knn_clf=None, model_path=None, distance_threshold=0.6):\\n    \\n    if not os.path.isfile(X_img_path) or os.path.splitext(X_img_path)[1][1:] not in ALLOWED_EXTENSIONS:\\n        raise Exception(\"Invalid image path: {}\".format(X_img_path))\\n\\n    if knn_clf is None and model_path is None:\\n        raise Exception(\"Must supply knn classifier either thourgh knn_clf or model_path\")\\n\\n    # Load a trained KNN model (if one was passed in)\\n    if knn_clf is None:\\n        with open(model_path, \\'rb\\') as f:\\n            knn_clf = pickle.load(f)\\n\\n    # Load image file and find face locations\\n    X_img = face_recognition.load_image_file(X_img_path)\\n    X_face_locations = face_recognition.face_locations(X_img)\\n\\n    # If no faces are found in the image, return an empty result.\\n    if len(X_face_locations) == 0:\\n        return []\\n\\n    # Find encodings for faces in the test iamge\\n    faces_encodings = face_recognition.face_encodings(X_img, known_face_locations=X_face_locations)\\n\\n    # Use the KNN model to find the best matches for the test face\\n    closest_distances = knn_clf.kneighbors(faces_encodings, n_neighbors=1)\\n    are_matches = [closest_distances[0][i][0] <= distance_threshold for i in range(len(X_face_locations))]\\n\\n    # Predict classes and remove classifications that aren\\'t within the threshold\\n    return [(pred, loc) if rec else (\"unknown\", loc) for pred, loc, rec in zip(knn_clf.predict(faces_encodings), X_face_locations, are_matches)]', 'def <mask>(img_path, predictions):\\n    \\n    pil_image = Image.open(img_path).convert(\"RGB\")\\n    draw = ImageDraw.Draw(pil_image)\\n\\n    for name, (top, right, bottom, left) in predictions:\\n        # Draw a box around the face using the Pillow module\\n        draw.rectangle(((left, top), (right, bottom)), outline=(0, 0, 255))\\n\\n        # There\\'s a bug in Pillow where it blows up with non-UTF-8 text\\n        # when using the default bitmap font\\n        name = name.encode(\"UTF-8\")\\n\\n        # Draw a label with a name below the face\\n        text_width, text_height = draw.textsize(name)\\n        draw.rectangle(((left, bottom - text_height - 10), (right, bottom)), fill=(0, 0, 255), outline=(0, 0, 255))\\n        draw.text((left + 6, bottom - text_height - 5), name, fill=(255, 255, 255, 255))\\n\\n    # Remove the drawing library from memory as per the Pillow docs\\n    del draw\\n\\n    # Display the resulting image\\n    pil_image.show()', 'def <mask>(rect):\\n    \\n    return rect.top(), rect.right(), rect.bottom(), rect.left()', 'def <mask>(css, image_shape):\\n    \\n    return max(css[0], 0), min(css[1], image_shape[1]), min(css[2], image_shape[0]), max(css[3], 0)', 'def <mask>(face_encodings, face_to_compare):\\n    \\n    if len(face_encodings) == 0:\\n        return np.empty((0))\\n\\n    return np.linalg.norm(face_encodings - face_to_compare, axis=1)', \"def <mask>(file, mode='RGB'):\\n    \\n    im = PIL.Image.open(file)\\n    if mode:\\n        im = im.convert(mode)\\n    return np.array(im)\", 'def <mask>(img, number_of_times_to_upsample=1, model=\"hog\"):\\n    \\n    if model == \"cnn\":\\n        return cnn_face_detector(img, number_of_times_to_upsample)\\n    else:\\n        return face_detector(img, number_of_times_to_upsample)', 'def <mask>(img, number_of_times_to_upsample=1, model=\"hog\"):\\n    \\n    if model == \"cnn\":\\n        return [_trim_css_to_bounds(_rect_to_css(face.rect), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, \"cnn\")]\\n    else:\\n        return [_trim_css_to_bounds(_rect_to_css(face), img.shape) for face in _raw_face_locations(img, number_of_times_to_upsample, model)]', 'def <mask>(images, number_of_times_to_upsample=1, batch_size=128):\\n    \\n    def convert_cnn_detections_to_css(detections):\\n        return [_trim_css_to_bounds(_rect_to_css(face.rect), images[0].shape) for face in detections]\\n\\n    raw_detections_batched = _raw_face_locations_batched(images, number_of_times_to_upsample, batch_size)\\n\\n    return list(map(convert_cnn_detections_to_css, raw_detections_batched))']\n",
            "['train', 'predict', 'show_prediction_labels_on_image', '_rect_to_css', '_trim_css_to_bounds', 'face_distance', 'load_image_file', '_raw_face_locations', 'face_locations', 'batch_face_locations']\n"
          ]
        }
      ],
      "source": [
        "print(val_inputs_raw[:10])\n",
        "print(val_labels_raw[:10])\n",
        "print(training_inputs_raw[:10])\n",
        "print(training_labels_raw[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Bs2QvVDHUIN"
      },
      "source": [
        "## Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "ec7ee1ef18b44b07b50e158a8adbe7ca",
            "7ba800be5d954261970a31c6ce294b69",
            "444cefde81bc4dff90664aee5f18b6af",
            "b21867dd30ea44218d714198cc60c99e",
            "6f4b40e3ad1c4aa4bd0c2f6a794e43fc",
            "3b85fe4575bb4969b9e296745b587520",
            "69e045e677ef4862a8bb321b0e6c9e9c",
            "cf664f7decff4a389c6a0046ce940506",
            "0dc7ce8e6b9b4c788b14fb29fe9d94aa",
            "9308302ef94c4d1f942ef35e17aaf35f",
            "ca15aff3664a4f3ebaf69e9ab20190c2",
            "d144a772d7e346c9934807029f6bd53e",
            "2cbdc33d3d6f4d0ea0a44b4c5ba8544b",
            "e0c34133ecc04a3e8a8b721917ae234f",
            "04d848d79fad48618b89a5010bd2246b",
            "b7e6edec8ce8467391fc5c87dde7f072",
            "2a3cafa4b3fe4a06897f9055df115f42",
            "9a543477a4d848e99fc1d39d7a6f7603",
            "25e8394c9cd84d65beaddffeb3815797",
            "fa1366f583e342328aa1a5b180bbe430",
            "1a98e6674a184c31b006f08fbb576ff1",
            "85278066a4304eaea74683590d9b4ec8",
            "18f042dbf9cb46eab10b02e4dbd0eecc",
            "4a45abea31d644a9a8308ddb272c5bcc",
            "d4659529995a4df3b7c85650b1bd43f5",
            "f87bc7cc49fc4004a3d83e4bb1fb3bb1",
            "43a8ed84a3b14dc9ada9e75f13e42fe7",
            "21edd439c0964a9cb9e0d18430b4e12d",
            "492a0e8183364ea4be0610214128d1f4",
            "535c78db3a654ad48646d3d8a08950fc",
            "1e319f38a55f4faeaa8dd80917d85a02",
            "f12368dbdace4b4da562346e4bb50bf5",
            "624def337fc04dcf9ebb118331fbe0b7",
            "1e0b9fc47585474d830d3da11be1cf35",
            "58af2eacd6544d4a861e91b6fafe93d9",
            "8f887822833a4f81bb94ac4f79b7e3f0",
            "a754205486ee4bae9daa76b109c2b5ed",
            "5786d874cf364649b516f3ae7ef8ea86",
            "9636154248fd404d9f6d44946dc36f16",
            "ba22f546e10942e98ae4595d89877cfd",
            "0d7a9b57eb5949d885a536fa12b321a4",
            "2b52ba8f80d844a3b0ef9f2cc92d553f",
            "d05ffede87924863a09e29090b012dae",
            "26696ae9e3ae4e3c9e9df0466043f634"
          ]
        },
        "id": "CbN7KjQtFfeP",
        "outputId": "630ac265-cc0c-4ea1-f5b3-ae3611e75f74"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec7ee1ef18b44b07b50e158a8adbe7ca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/994k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d144a772d7e346c9934807029f6bd53e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18f042dbf9cb46eab10b02e4dbd0eecc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/19.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e0b9fc47585474d830d3da11be1cf35",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/480 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1356 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ],
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained(\"huggingface/CodeBERTa-small-v1\")\n",
        "\n",
        "PAD_token = tokenizer.pad_token_id\n",
        "EOS_token = tokenizer.eos_token_id\n",
        "BOS_token = tokenizer.bos_token_id\n",
        "\n",
        "training_inputs = tokenizer.batch_encode_plus(training_inputs_raw)[\"input_ids\"]\n",
        "training_labels = tokenizer.batch_encode_plus(training_labels_raw)[\"input_ids\"]\n",
        "\n",
        "val_inputs = tokenizer.batch_encode_plus(val_inputs_raw)[\"input_ids\"]\n",
        "val_labels = tokenizer.batch_encode_plus(val_labels_raw)[\"input_ids\"]\n",
        "\n",
        "\n",
        "#Remove underscore tokens from inputs and labels, and truncate up to max model length\n",
        "underscore_token = tokenizer.get_vocab()[\"_\"]\n",
        "\n",
        "training_inputs = [[token for token in input if token != underscore_token][:tokenizer.model_max_length] for input in training_inputs]\n",
        "training_labels = [[token for token in input if token != underscore_token] for input in training_labels]\n",
        "\n",
        "val_inputs = [[token for token in input if token != underscore_token][:tokenizer.model_max_length] for input in val_inputs]\n",
        "val_labels = [[token for token in input if token != underscore_token] for input in val_labels]\n",
        "\n",
        "\n",
        "\n",
        "training_pairs = list(zip(training_inputs,training_labels))\n",
        "validation_pairs = list(zip(val_inputs,val_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JRIng5UdBJNb",
        "outputId": "9cc43af1-71b9-4980-8180-2bdd7a4ddec6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0, 417, 4, 12, 2149, 16, 203, 620, 3286, 16, 203, 620, 7002, 33, 923, 16, 203, 620, 17339, 33, 25, 73, 17, 24, 16, 203, 620, 2904, 33996, 33, 28582, 16, 203, 620, 2433, 914, 33, 25, 2545, 16, 203, 620, 30602, 35150, 11228, 33, 20, 18, 21, 16, 203, 620, 30602, 35150, 1242, 9311, 33, 20, 18, 2603, 16, 203, 620, 5184, 7119, 33, 21, 16, 203, 620, 3450, 914, 33, 1462, 16, 203, 620, 1492, 7119, 33, 4036, 16, 203, 620, 11920, 7119, 33, 14226, 16, 203, 620, 11920, 578, 33, 923, 16, 203, 620, 16584, 16669, 33, 7545, 16, 203, 620, 11893, 33, 21, 18, 20, 16, 203, 620, 1503, 3280, 1408, 7119, 33, 8481, 16, 203, 620, 7987, 28398, 21921, 33, 1526, 16, 203, 620, 7987, 28398, 21921, 4157, 33, 20, 18, 26, 16, 203, 620, 7987, 28398, 21921, 5141, 20, 33, 20, 18, 24, 16, 203, 620, 7987, 28398, 21921, 5141, 18611, 33, 923, 16, 203, 620, 7987, 28398, 21921, 9311, 33, 21, 73, 17, 26, 16, 203, 620, 897, 11924, 33, 1526, 16, 203, 620, 1826, 33, 923, 16, 203, 620, 1902, 578, 33, 923, 16, 203, 620, 1381, 3280, 1473, 203, 278, 5245, 203, 2428, 263, 471, 2595, 1047, 343, 5411, 5882, 386, 5184, 343, 1547, 203, 203, 263, 13077, 272, 548, 1724, 314, 203, 263, 715, 3538, 23165, 12, 6712, 13, 203, 203, 263, 2013, 617, 272, 2093, 85, 617, 12, 3280, 16, 1381, 3280, 1473, 13, 203, 203, 263, 471, 10028, 343, 3272, 9215, 343, 12871, 1138, 848, 343, 3381, 976, 403, 512, 8710, 203, 263, 471, 836, 7880, 15344, 1641, 42877, 1463, 8249, 793, 203, 203, 263, 13694, 1057, 272, 3381, 18, 18052, 1057, 203, 263, 1727, 1463, 8249, 793, 12, 406, 454, 203, 267, 345, 13944, 9120, 1177, 12, 18052, 1057, 16, 652, 33, 406, 13, 203, 203, 263, 1850, 16, 5184, 16, 1702, 1444, 16, 3566, 272, 9381, 85, 18, 1783, 5229, 12, 203, 267, 1463, 8249, 793, 33, 2813, 8249, 793, 16, 203, 267, 2013, 617, 33, 85, 617, 16, 203, 267, 1439, 3508, 33, 2149, 18, 1026, 1057, 18, 82, 16, 203, 267, 16990, 33, 4234, 18, 5229, 18, 1833, 359, 25913, 12, 15163, 4399, 33, 9448, 582, 203, 267, 11893, 33, 11699, 16, 203, 267, 6848, 5559, 2613, 7017, 33, 1507, 16, 203, 267, 897, 11924, 33, 567, 11924, 203, 263, 554, 203, 203, 263, 1850, 969, 272, 284, 203, 267, 318, 2813, 8249, 793, 660, 1463, 8249, 793, 16, 203, 267, 318, 85, 617, 660, 2013, 617, 16, 203, 267, 318, 1333, 3508, 660, 3381, 18, 1026, 1057, 18, 82, 16, 203, 263, 302, 203, 203, 263, 1850, 272, 7042, 3845, 12, 672, 16, 1850, 969, 13, 203, 203, 263, 471, 2595, 343, 22714, 2433, 203, 263, 317, 7987, 28398, 21921, 30, 203, 267, 22714, 2156, 272, 41559, 28398, 25423, 1577, 12, 2156, 914, 16, 5219, 33, 41639, 21921, 4157, 13, 203, 267, 317, 7987, 28398, 21921, 5141, 18611, 403, 717, 30, 203, 278, 7987, 28398, 21921, 5141, 18611, 272, 2904, 33996, 203, 267, 8750]\n"
          ]
        }
      ],
      "source": [
        "print(val_inputs[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6L5WlPiSjvWc"
      },
      "source": [
        "## Set Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxzGZJKpjuca"
      },
      "outputs": [],
      "source": [
        "class Config:\n",
        "    \"\"\"\n",
        "    Stores useful information\n",
        "    Many scripts uses a config instance. See utils.create_session for its initialization\n",
        "    \"\"\"\n",
        "    \n",
        "    model_type = \"CodeBERTa\" #CodeBERTa, RNNEncoder or CNNEncoder\n",
        "    model_name = \"huggingface/CodeBERTa-small-v1\"\n",
        "    use_attention = False # use attention for RNNEncoder model\n",
        "    tie_embeddings = False # do tie embeddings between encoders and decoders (for RNNEncoder and CNNEncoder models)\n",
        "\n",
        "    dataset_size = \"small\"\n",
        "    data_folder = \"data\"\n",
        "\n",
        "    print_every_k_batch = 256\n",
        "    batch_size = 16\n",
        "    learning_rate = 1e-5\n",
        "    embedding_dim = 128\n",
        "    hidden_size = 128\n",
        "    epochs = 10\n",
        "    weight_decay = 0\n",
        "    drop_rate = .2\n",
        "    max_grad_norm = 2. #max norm for gradient clipping\n",
        "\n",
        "    path_result = \"\"\n",
        "    # Can set the resume checkpoint if model retraining is necessary\n",
        "    resume = None\n",
        "    # resume = \"/content/drive/MyDrive/codenet_data/checkpoint_small.pth\"\n",
        "    num_return_sequences = 5 #number of sequences to return when making prediction with the models\n",
        "    max_output_seq_len = 8\n",
        "    max_input_len = 200\n",
        "    bos_token_id = 0\n",
        "    pad_token_id = 1\n",
        "    eos_token_id = 2\n",
        "    mask_token_id = 3\n",
        "\n",
        "    def __init__(self, args={}):\n",
        "        for attr in dir(self):\n",
        "            if not attr.startswith('__') and hasattr(args, attr):\n",
        "                setattr(self, attr, getattr(args, attr))\n",
        "\n",
        "    def __repr__(self):\n",
        "        return json.dumps(vars(self), sort_keys=True, indent=4)\n",
        "config = Config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xU3bhVCVkc8y"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XDtKMiE9kedH"
      },
      "outputs": [],
      "source": [
        "def pretty_time(t):\n",
        "    \"\"\"\n",
        "    Tranforms time t in seconds into a pretty string\n",
        "    \"\"\"\n",
        "    return f\"{int(t//60)}m{int(t%60)}s\"\n",
        "    \n",
        "def now():\n",
        "    \"\"\"\n",
        "    Current date as a string\n",
        "    \"\"\"\n",
        "    return datetime.now().strftime('%y-%m-%d_%Hh%Mm%Ss')\n",
        "\n",
        "def save_json(path_result, name, x):\n",
        "    \"\"\"\n",
        "    Saves x into path_result with the given name\n",
        "    \"\"\"\n",
        "    with open(os.path.join(path_result, f'{name}.json'), 'w') as f:\n",
        "        json.dump(x, f, indent=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abJN_MKgHXSa"
      },
      "source": [
        "## Build Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jcc8EzJBG08i"
      },
      "outputs": [],
      "source": [
        "class FunctionNamingDataset(Dataset):\n",
        "    def __init__(self,data_pairs,inputs_raw):\n",
        "        self.pairs = data_pairs\n",
        "        self.inputs_raw = inputs_raw\n",
        "        self.n_examples = len(self.pairs)\n",
        "    \n",
        "    def __len__(self):\n",
        "        r\"\"\"When used `len` return the number of examples.\n",
        "        \"\"\"\n",
        "\n",
        "        return self.n_examples\n",
        "\n",
        "\n",
        "    def __getitem__(self, item):\n",
        "        r\"\"\"Given an index return a pair of input output\n",
        "        \"\"\"\n",
        "        input,output = self.pairs[item]\n",
        "        input_raw = self.inputs_raw[item]\n",
        "        return (input,output,len(input),len(output),input_raw)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7cSyUM-eG5Wt"
      },
      "outputs": [],
      "source": [
        "train_dataset = FunctionNamingDataset(training_pairs,training_inputs_raw)\n",
        "val_dataset = FunctionNamingDataset(validation_pairs,val_inputs_raw)\n",
        "\n",
        "\n",
        "train_batch_size = config.batch_size\n",
        "valid_batch_size = config.batch_size\n",
        "\n",
        "train_dataloader,val_dataloader = BucketIterator.splits(\n",
        "    \n",
        "                        # Datasets for iterator to draw data from\n",
        "                        (train_dataset,val_dataset),\n",
        "\n",
        "                        # Tuple of train and validation batch sizes.\n",
        "                        batch_sizes=(train_batch_size,valid_batch_size),\n",
        "\n",
        "                        # Device to load batches on.\n",
        "                        device=device, \n",
        "\n",
        "                        # Function to use for sorting examples.\n",
        "                        sort_key=lambda x: x[2],\n",
        "\n",
        "\n",
        "                        # Repeat the iterator for multiple epochs.\n",
        "                        repeat=True, \n",
        "\n",
        "                        # Sort all examples in data using `sort_key`.\n",
        "                        sort=False, \n",
        "\n",
        "                        # Shuffle data on each epoch run.\n",
        "                        shuffle=True,\n",
        "\n",
        "                        # Use `sort_key` to sort examples in each batch.\n",
        "                        sort_within_batch=True,\n",
        "                        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCfBhVgkHczq"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFpmWiNohjiS"
      },
      "source": [
        "## LayerDrop ModuleList Class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TWBIpdeLhsk7"
      },
      "outputs": [],
      "source": [
        "# Support class for LayerDrop implementation. The source code of this class is\n",
        "# from https://fairseq.readthedocs.io/en/latest/_modules/fairseq/modules/layer_drop.html#LayerDropModuleList\n",
        "class LayerDropModuleList(torch.nn.ModuleList):\n",
        "    \"\"\"\n",
        "    A LayerDrop implementation based on :class:`torch.nn.ModuleList`.\n",
        "\n",
        "    We refresh the choice of which layers to drop every time we iterate\n",
        "    over the LayerDropModuleList instance. During evaluation we always\n",
        "    iterate over all layers.\n",
        "\n",
        "    Usage::\n",
        "\n",
        "        layers = LayerDropList(p=0.5, modules=[layer1, layer2, layer3])\n",
        "        for layer in layers:  # this might iterate over layers 1 and 3\n",
        "            x = layer(x)\n",
        "        for layer in layers:  # this might iterate over all layers\n",
        "            x = layer(x)\n",
        "        for layer in layers:  # this might not iterate over any layers\n",
        "            x = layer(x)\n",
        "\n",
        "    Args:\n",
        "        p (float): probability of dropping out each layer\n",
        "        modules (iterable, optional): an iterable of modules to add\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, p, modules=None):\n",
        "        super().__init__(modules)\n",
        "        self.p = p\n",
        "\n",
        "    def __iter__(self):\n",
        "        dropout_probs = torch.empty(len(self)).uniform_()\n",
        "        for i, m in enumerate(super().__iter__()):\n",
        "            if not self.training or (dropout_probs[i] > self.p):\n",
        "                yield m"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mh_igHXWM_v"
      },
      "source": [
        "## Model Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1k3VOpujMdP"
      },
      "outputs": [],
      "source": [
        "bcolors = {\n",
        "    'RESULTS': '\\033[95m',\n",
        "    'HEADER': '\\033[94m',\n",
        "    'SUCCESS': '\\033[92m',\n",
        "    'WARNING': '\\033[93m',\n",
        "    'FAIL': '\\033[91m',\n",
        "    'ENDC': '\\033[0m',\n",
        "    'INFO': '\\033[1m',\n",
        "    'UNDERLINE': '\\033[4m'\n",
        "}\n",
        "\n",
        "def printc(log, color='HEADER'):\n",
        "    \"\"\"\n",
        "    Prints logs with color according to the dict bcolors\n",
        "    \"\"\"\n",
        "    print(f\"{bcolors[color]}{log}{bcolors['ENDC']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DdF7BkYWOrW"
      },
      "outputs": [],
      "source": [
        "class Seq2SeqModelInterface(torch.nn.Module):\n",
        "    def __init__(self,config,device):\n",
        "        \"\"\"\n",
        "        PyTorch Seq2SeqModel interface\n",
        "        Every model has to inherit from Seq2SeqModelInterface so training and testing run correctly\n",
        "\n",
        "        At least the methods defined below and which raise NotImplementedError must be implemented\n",
        "        - self.optimizer\n",
        "        - self.scheduler\n",
        "        \"\"\"\n",
        "        super(Seq2SeqModelInterface, self).__init__()\n",
        "        self.device = device\n",
        "        self.config = config\n",
        "        \n",
        "    def initialize_scheduler(self, total_steps=0):\n",
        "        \"\"\"\n",
        "        Creates a scheduler for a given otimizer\n",
        "        \"\"\"\n",
        "        self.scheduler = get_linear_schedule_with_warmup(self.optimizer,\n",
        "                                                        num_warmup_steps=2, # Default value\n",
        "                                                        num_training_steps=total_steps)\n",
        "    def resume(self, config):\n",
        "        \"\"\"\n",
        "        Resumes with a given checkpoint. Loads the saved parameters, optimizer and scheduler.\n",
        "        \"\"\"\n",
        "        printc(f\"Resuming with model at {config.resume}...\", \"INFO\")\n",
        "        path_checkpoint = config.resume\n",
        "        assert os.path.isfile(path_checkpoint), 'Error: no checkpoint found!'\n",
        "        checkpoint = torch.load(path_checkpoint, map_location=self.device)\n",
        "        \n",
        "        self.load_state_dict(checkpoint['model'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "        self.scheduler.load_state_dict(checkpoint['scheduler'])\n",
        "\n",
        "    def step(self, batch):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            batch: data from the data loaders (see training.py)\n",
        "        Output:\n",
        "            loss (tensor): PyTorch loss\n",
        "            outputs (batch_size,seq_len,vocab_size): model outputs (raw predictions without softmax)\n",
        "        \n",
        "        Examples::\n",
        "            >>> batch = next(iter(train_loader))\n",
        "            >>> loss, outputs = model.step(batch)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def forward(self,*args, **kwargs):\n",
        "        \"\"\"\n",
        "        PyTorch nn.Module forward\n",
        "        It is specific to the model, and the args have no specific format\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def evaluate(self, batch, num_sequences=1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            batch: data from the data loaders (similar to training data)\n",
        "            num_sequences: the number of sequences to output \n",
        "        Output:\n",
        "            top_seqences(batch_size,num_sequences,max_output_seq_len): The top num_sequences predictions\n",
        "            top_lengths(batch_size,num_sequences): The actual lengths of the top num_sequences predictions\n",
        "            target_sequences(batch_size,batch_tgt_max_seq_len): The target sequences corresponding to the predicted ones for metrics computation\n",
        "            target_lengths(batch_size): The actual lengths of the top target sequences\n",
        "            decoded_sequences List[List[string] * num_sequences]*batch_size: The top num_sequences predictions decoded (as strings)\n",
        "            outputs_probability (batch_size,num_sequences,max_output_seq_len - 1, vocab_size): model outputs passed through a softmax to turn into probabilities\n",
        "        \n",
        "        Examples::\n",
        "            >>> batch = next(iter(eval_loader))\n",
        "            >>> (top_seqences,top_lengths,target_sequences, target_lengths, \n",
        "                decoded_sequences,outputs_probability) = model.evaluate(batch,num_sequences=num_output_sequences)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def single_inference(self, function_string, num_sequences=1):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            function_string: raw text data (i.e a function extracted using ast)\n",
        "            num_sequences: the number of sequences to output \n",
        "        Output:\n",
        "            decoded_sequence [num_sequences]: The top num_sequences predictions decoded (as strings)\n",
        "            sequence_scores [num_sequences]: Probability for each sequence\n",
        "        \n",
        "        Examples:\n",
        "            >>> decoded_sequences,sequence_scores = model.single_inference(function_string,num_sequences=num_output_sequences)\n",
        "        \"\"\"\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94AUOYr4-MvU"
      },
      "outputs": [],
      "source": [
        "# Helper function to implement LayerDrop in the model directly\n",
        "def apply_layerdrop(model, layerdrop_rate=0.2):\n",
        "    oldModuleList = model.encoder.encoder.layer\n",
        "    newModuleList = LayerDropModuleList(0.2)\n",
        "\n",
        "    # Now iterate over all layers, only keeping the relevant layers.\n",
        "    for i in range(6):\n",
        "        newModuleList.append(oldModuleList[i])\n",
        "\n",
        "    # create a copy of the model, modify it with the new list, and return\n",
        "    copyOfModel = copy.deepcopy(model)\n",
        "    copyOfModel.encoder.encoder.layer = newModuleList\n",
        "\n",
        "    return copyOfModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKvQPz_IbW7A"
      },
      "outputs": [],
      "source": [
        "def set_dropout(model, drop_rate=0.1):\n",
        "    for _, child in model.named_children():\n",
        "        if isinstance(child, torch.nn.Dropout):\n",
        "            child.p = drop_rate\n",
        "        set_dropout(child, drop_rate=drop_rate)\n",
        "\n",
        "class CodeBERTaEncoderDecoder(Seq2SeqModelInterface):\n",
        "    def __init__(self,config,device, layerdrop=False, layerdrop_rate=0):\n",
        "        \"\"\"\n",
        "        RoBERTa to RoBERTa encoder-decoder using HuggingFace pretrained CodeBERTa models trained on the CodeNet challenge dataset on LM tasks.\n",
        "        Elements in training batch for this model should be tuples (inputs,labels,inputs_lengths,labels_lengths). \n",
        "        Inputs and labels do not need any padding.\n",
        "        \"\"\"\n",
        "        super(CodeBERTaEncoderDecoder, self).__init__(config,device)\n",
        "        self.config = config\n",
        "        assert config.model_type == \"CodeBERTa\", 'Error: Wrong model type!'\n",
        "\n",
        "        self.model_name = config.model_name\n",
        "        self.model = EncoderDecoderModel.from_encoder_decoder_pretrained(self.model_name, self.model_name).to(self.device)\n",
        "        if layerdrop == True:\n",
        "            self.model = apply_layerdrop(self.model, layerdrop_rate)\n",
        "        self.tokenizer = RobertaTokenizer.from_pretrained(self.model_name)\n",
        "\n",
        "        self.max_output_seq_len = config.max_output_seq_len\n",
        "        self.learning_rate = config.learning_rate\n",
        "        self.max_grad_norm = config.max_grad_norm\n",
        "\n",
        "        self.optimizer = Adam(self.model.parameters(), lr = self.learning_rate, weight_decay=config.weight_decay)\n",
        "        self.scheduler = ReduceLROnPlateau(self.optimizer)\n",
        "\n",
        "        if config.resume:\n",
        "            self.resume(config)\n",
        "        printc(\"Successfully loaded\\n\", \"SUCCESS\")\n",
        "\n",
        "        self.drop_rate = config.drop_rate\n",
        "        if self.drop_rate:\n",
        "            set_dropout(self.model, drop_rate=self.drop_rate)\n",
        "            print(f\"Dropout rate set to {self.drop_rate}\")\n",
        "            \n",
        "\n",
        "    def get_models_inputs_from_pair_batch(self,batch):\n",
        "        batch_size = len(batch)\n",
        "        unzipped = list(zip(*batch))\n",
        "        inputs,targets,inputs_lengths,targets_lengths,inputs_raw = unzipped[0],unzipped[1],unzipped[2],unzipped[3],unzipped[4]\n",
        "\n",
        "        PAD_token = self.tokenizer.pad_token_id\n",
        "\n",
        "        #Build input tensor and pad\n",
        "        inputs_lengths_tensor = torch.LongTensor(inputs_lengths)\n",
        "        inputs_tensor = torch.ones(batch_size,inputs_lengths_tensor.max()).long() * PAD_token\n",
        "        for idx, (seq, seqlen) in enumerate(zip(inputs, inputs_lengths_tensor)):\n",
        "            inputs_tensor[idx,:seqlen] = torch.LongTensor(seq)\n",
        "\n",
        "        inputs_attention_mask = (inputs_tensor != PAD_token) * 1\n",
        "\n",
        "        #Build target tensor and pad\n",
        "        targets_lengths_tensor = torch.LongTensor(targets_lengths)\n",
        "        targets_tensor = torch.ones(batch_size,targets_lengths_tensor.max()).long() * PAD_token\n",
        "\n",
        "        for idx, (seq, seqlen) in enumerate(zip(targets, targets_lengths_tensor)):\n",
        "            targets_tensor[idx,:seqlen] = torch.LongTensor(seq)\n",
        "\n",
        "        targets_attention_mask = (targets_tensor != PAD_token) * 1\n",
        "\n",
        "        return (inputs_tensor, targets_tensor,targets_lengths_tensor,inputs_attention_mask,targets_attention_mask,inputs_raw)\n",
        "\n",
        "    def step(self, batch):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            batch: a batch of training data in the form described above in init\n",
        "        Output:\n",
        "            loss (tensor): PyTorch loss\n",
        "            outputs (batch_size,seq_len,vocab_size): model outputs (predictions or something else)\n",
        "        \"\"\"\n",
        "        #Unpack batch data\n",
        "        src_seqs,tgt_seqs,tgt_lens,src_mask,tgt_mask,_ = self.get_models_inputs_from_pair_batch(batch)\n",
        "        \n",
        "        src_seqs = src_seqs.to(self.device)\n",
        "        tgt_seqs = tgt_seqs.to(self.device)\n",
        "\n",
        "        tgt_lens = tgt_lens.to(self.device)\n",
        "\n",
        "        src_mask = src_mask.to(self.device)\n",
        "        tgt_mask = tgt_mask.to(self.device)\n",
        "        # -------------------------------------\n",
        "        # Training mode (enable dropout)\n",
        "        # -------------------------------------\n",
        "        self.model.train()    \n",
        "\n",
        "        loss,outputs = self.forward(src_seqs,tgt_seqs,src_mask,tgt_mask)\n",
        "        # -------------------------------------\n",
        "        # Backward and optimize\n",
        "        # -------------------------------------\n",
        "        # Backward to get gradients w.r.t parameters in model.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip gradients\n",
        "        torch.nn.utils.clip_grad_norm_(self.model.parameters(),max_norm=self.max_grad_norm)\n",
        "        \n",
        "        # Update parameters with optimizer\n",
        "        self.optimizer.step()\n",
        "\n",
        "        return loss,outputs\n",
        "            \n",
        "\n",
        "    def forward(self,src_seqs,tgt_seqs,src_mask,tgt_mask):\n",
        "        output = self.model(input_ids=src_seqs,decoder_input_ids=tgt_seqs,labels=tgt_seqs,encoder_attention_mask=src_mask,decoder_attention_mask=tgt_mask)\n",
        "        return output.loss,output.logits\n",
        "\n",
        "    def evaluate(self, eval_batch, max_seq_len=None,num_return_sequences=None,num_beams=5):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            eval_batch: batch data in the same form as train data (described in init)\n",
        "            num_sequences: the number of sequences to output \n",
        "            max_seq_len: Maximum output sequence length\n",
        "            num_beams: Number of beams for beam search. \n",
        "        Output:\n",
        "            top_seqences(batch_size,num_sequences,max_seq_len): The top num_sequences predictions\n",
        "            top_lengths(batch_size,num_sequences): The actual lengths of the top num_sequences predictions\n",
        "            target_sequences(batch_size,batch_tgt_max_seq_len): The target sequences corresponding to the predicted ones for metrics computation\n",
        "            target_lengths(batch_size): The actual lengths of the top target sequences\n",
        "            decoded_sequences List[List[string] * num_sequences]*batch_size: The top num_sequences predictions decoded (as strings)\n",
        "            outputs_probability (batch_size,num_sequences,max_seq_len - 1, vocab_size): model outputs passed through a softmax to turn into probabilities\n",
        "        \"\"\"\n",
        "        if max_seq_len is None:\n",
        "            max_seq_len = self.config.max_output_seq_len\n",
        "        if num_return_sequences is None:\n",
        "            num_return_sequences = self.config.num_return_sequences\n",
        "        with torch.no_grad():\n",
        "            batch_size = len(eval_batch)\n",
        "\n",
        "            #Unpack batch data\n",
        "            src_seqs,tgt_seqs,tgt_lens,_,_,inputs_raw = self.get_models_inputs_from_pair_batch(eval_batch)\n",
        "\n",
        "            src_seqs = src_seqs.to(self.device)\n",
        "            tgt_seqs = tgt_seqs.to(self.device)\n",
        "            tgt_lens = tgt_lens.to(self.device)\n",
        "\n",
        "\n",
        "            # -------------------------------------\n",
        "            # Eval mode mode (disable dropout)\n",
        "            # -------------------------------------\n",
        "            self.model.eval()\n",
        "\n",
        "            # -------------------------------------\n",
        "            # Forward model\n",
        "            # -------------------------------------\n",
        "            start_beam_search = time()\n",
        "            beam_output = self.model.generate(\n",
        "                                src_seqs, \n",
        "                                max_length=self.max_output_seq_len, \n",
        "                                num_beams=num_beams, \n",
        "                                num_return_sequences=num_return_sequences, \n",
        "                                early_stopping=True,\n",
        "                                output_scores = True,\n",
        "                                return_dict_in_generate=True,\n",
        "                                no_repeat_ngram_size = 1,\n",
        "                                eos_token_id = self.tokenizer.eos_token_id,\n",
        "                                pad_token_id = self.tokenizer.eos_token_id\n",
        "                            )\n",
        "            beam_search_time = time() - start_beam_search\n",
        "            #top_sequence = (batch_size,num_sequences,max_seq_len)\n",
        "            #top_length = (batch_size,num_sequences)\n",
        "            top_sequence = beam_output[\"sequences\"].view(batch_size,num_return_sequences,beam_output[\"sequences\"].size(1))\n",
        "            # non zero values mask\n",
        "            eos_mask = top_sequence == self.tokenizer.eos_token_id\n",
        "\n",
        "            # operations on the mask to find first EOS_token in the rows\n",
        "            mask_max_values, eos_index = torch.max(eos_mask, dim=2)\n",
        "            # Actual length is one more than the index\n",
        "            top_length = eos_index + 1\n",
        "\n",
        "            # if the max-mask is zero, there is no pad index in the row, the length is the length of the sequence\n",
        "            top_length[mask_max_values == 0] = top_sequence.size(2)\n",
        "\n",
        "            #get output probabilites\n",
        "            outputs = torch.stack(beam_output['scores']).transpose(0,1).view(batch_size,num_return_sequences,beam_output[\"sequences\"].size(1) - 1,self.tokenizer.vocab_size)\n",
        "            output_prob = torch.nn.functional.softmax(outputs,dim=3)\n",
        "            #decode sequences and add _\n",
        "            to_decode_full_batch = []\n",
        "            for i in range(batch_size):\n",
        "                to_decode_single_batch = []\n",
        "                for j in range(num_return_sequences):\n",
        "                    top_sequence_to_decode = [self.tokenizer.convert_tokens_to_ids(\"_\")] * (len(top_sequence[i][j]) * 2 - 1)\n",
        "                    top_sequence_to_decode[0::2] = top_sequence[i][j]\n",
        "                    to_decode_single_batch.append(top_sequence_to_decode)\n",
        "                to_decode_full_batch.append(to_decode_single_batch)\n",
        "            \n",
        "\n",
        "            #decode sequences\n",
        "            decoded_sequences = [self.tokenizer.batch_decode(to_decode_full_batch[i],skip_special_tokens=True) for i in range(batch_size)]\n",
        "\n",
        "            del outputs,src_seqs,eos_index,eos_mask,mask_max_values,beam_output\n",
        "\n",
        "        return top_sequence,top_length,tgt_seqs,tgt_lens,output_prob,decoded_sequences,inputs_raw\n",
        "\n",
        "    def single_inference(self, function_string,num_return_sequences=None):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            function_string: raw text data (i.e a function extracted using ast)\n",
        "            num_sequences: the number of sequences to output \n",
        "        Output:\n",
        "            decoded_sequence [num_sequences]: The top num_sequences predictions decoded (as strings)\n",
        "            sequence_scores [num_sequences]: Probability for each sequence\n",
        "        \"\"\"\n",
        "        raise NotImplementedError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQEDAUbayuWz"
      },
      "source": [
        "## Load Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "94700731c6ff4bcaaf5e6583d79a5e95",
            "0c609e3d558e4de0896282e75a577685",
            "0cd53a624a814029b0b57321bab52e25",
            "f055bc5b9d6148ed9652727b9d9d7ff1",
            "9e44c8fa5cbe4625bd9673ea4ffe420a",
            "ae8792d73bde4b00a63bcf120cb96c84",
            "857db07640264b81acb094b6729b7a94",
            "c3157e9cc2bd4ea2b900cf7d452b287d",
            "42bdc541d56e495da3b81c115209d91c",
            "07f3c7ab2d014a259efe07646edca45c",
            "555f8f3ce59b4f9ba0489ab140a69c0c"
          ]
        },
        "id": "QI3RJrvWj2xj",
        "outputId": "293ebb8d-c77a-45cd-b048-2894cdfff363"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94700731c6ff4bcaaf5e6583d79a5e95",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/336M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at huggingface/CodeBERTa-small-v1 were not used when initializing RobertaModel: ['lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.bias', 'lm_head.dense.weight']\n",
            "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at huggingface/CodeBERTa-small-v1 and are newly initialized: ['roberta.encoder.layer.1.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.output.dense.bias', 'roberta.encoder.layer.2.crossattention.self.query.weight', 'roberta.encoder.layer.5.crossattention.self.key.weight', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.4.crossattention.self.key.bias', 'roberta.encoder.layer.5.crossattention.self.value.bias', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.2.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.key.weight', 'roberta.encoder.layer.3.crossattention.self.query.bias', 'roberta.encoder.layer.5.crossattention.self.value.weight', 'roberta.encoder.layer.2.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.output.dense.bias', 'roberta.encoder.layer.4.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.2.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.query.bias', 'roberta.encoder.layer.0.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.3.crossattention.output.dense.weight', 'roberta.encoder.layer.3.crossattention.self.value.bias', 'roberta.encoder.layer.3.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.query.bias', 'roberta.encoder.layer.4.crossattention.output.dense.bias', 'roberta.encoder.layer.0.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.self.value.weight', 'roberta.encoder.layer.5.crossattention.output.dense.weight', 'roberta.encoder.layer.5.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.self.key.weight', 'roberta.encoder.layer.5.crossattention.self.query.bias', 'roberta.encoder.layer.2.crossattention.self.value.bias', 'roberta.encoder.layer.2.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.value.bias', 'roberta.encoder.layer.0.crossattention.self.value.weight', 'roberta.encoder.layer.3.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.self.key.bias', 'roberta.encoder.layer.1.crossattention.self.query.bias', 'roberta.encoder.layer.1.crossattention.output.dense.bias', 'roberta.encoder.layer.1.crossattention.self.key.bias', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.0.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.1.crossattention.self.query.weight', 'roberta.encoder.layer.2.crossattention.output.dense.weight', 'roberta.encoder.layer.1.crossattention.output.dense.weight', 'roberta.encoder.layer.4.crossattention.self.query.weight', 'roberta.encoder.layer.0.crossattention.self.query.weight', 'roberta.encoder.layer.3.crossattention.output.LayerNorm.bias', 'roberta.encoder.layer.5.crossattention.self.key.bias', 'roberta.encoder.layer.4.crossattention.self.value.weight', 'roberta.encoder.layer.4.crossattention.self.key.weight', 'roberta.encoder.layer.1.crossattention.output.LayerNorm.weight', 'roberta.encoder.layer.4.crossattention.output.LayerNorm.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[92mSuccessfully loaded\n",
            "\u001b[0m\n",
            "Dropout rate set to 0.2\n"
          ]
        }
      ],
      "source": [
        "model = CodeBERTaEncoderDecoder(config,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5nKMWgjjuTL",
        "outputId": "c2122712-d277-4f04-e3b3-8707662c82ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CodeBERTaEncoderDecoder(\n",
            "  (model): EncoderDecoderModel(\n",
            "    (encoder): RobertaModel(\n",
            "      (embeddings): RobertaEmbeddings(\n",
            "        (word_embeddings): Embedding(52000, 768, padding_idx=1)\n",
            "        (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "        (token_type_embeddings): Embedding(1, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (encoder): RobertaEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.2, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.2, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.2, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.2, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.2, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): RobertaLayer(\n",
            "            (attention): RobertaAttention(\n",
            "              (self): RobertaSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "              (output): RobertaSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): RobertaIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            )\n",
            "            (output): RobertaOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.2, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (pooler): RobertaPooler(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (activation): Tanh()\n",
            "      )\n",
            "    )\n",
            "    (decoder): RobertaForCausalLM(\n",
            "      (roberta): RobertaModel(\n",
            "        (embeddings): RobertaEmbeddings(\n",
            "          (word_embeddings): Embedding(52000, 768, padding_idx=1)\n",
            "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
            "          (token_type_embeddings): Embedding(1, 768)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "        (encoder): RobertaEncoder(\n",
            "          (layer): ModuleList(\n",
            "            (0): RobertaLayer(\n",
            "              (attention): RobertaAttention(\n",
            "                (self): RobertaSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "                (output): RobertaSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (crossattention): RobertaAttention(\n",
            "                (self): RobertaSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "                (output): RobertaSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): RobertaIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): RobertaOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (1): RobertaLayer(\n",
            "              (attention): RobertaAttention(\n",
            "                (self): RobertaSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "                (output): RobertaSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (crossattention): RobertaAttention(\n",
            "                (self): RobertaSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "                (output): RobertaSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): RobertaIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): RobertaOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (2): RobertaLayer(\n",
            "              (attention): RobertaAttention(\n",
            "                (self): RobertaSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "                (output): RobertaSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (crossattention): RobertaAttention(\n",
            "                (self): RobertaSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "                (output): RobertaSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): RobertaIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): RobertaOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (3): RobertaLayer(\n",
            "              (attention): RobertaAttention(\n",
            "                (self): RobertaSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "                (output): RobertaSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (crossattention): RobertaAttention(\n",
            "                (self): RobertaSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "                (output): RobertaSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): RobertaIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): RobertaOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (4): RobertaLayer(\n",
            "              (attention): RobertaAttention(\n",
            "                (self): RobertaSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "                (output): RobertaSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (crossattention): RobertaAttention(\n",
            "                (self): RobertaSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "                (output): RobertaSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): RobertaIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): RobertaOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (5): RobertaLayer(\n",
            "              (attention): RobertaAttention(\n",
            "                (self): RobertaSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "                (output): RobertaSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (crossattention): RobertaAttention(\n",
            "                (self): RobertaSelfAttention(\n",
            "                  (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "                (output): RobertaSelfOutput(\n",
            "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                  (dropout): Dropout(p=0.2, inplace=False)\n",
            "                )\n",
            "              )\n",
            "              (intermediate): RobertaIntermediate(\n",
            "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              )\n",
            "              (output): RobertaOutput(\n",
            "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.2, inplace=False)\n",
            "              )\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (lm_head): RobertaLMHead(\n",
            "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "        (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "        (decoder): Linear(in_features=768, out_features=52000, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UdhFQyjFxOi"
      },
      "source": [
        "## Evaluation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-SZHfjYmweob"
      },
      "outputs": [],
      "source": [
        "def get_acc_and_f1_values(tgt_seqs,pred_seqs,tgt_lens,pred_lens):\n",
        "    batch_size = tgt_seqs.size(0)\n",
        "    #get numpy arrays\n",
        "    tgt_seqs = tgt_seqs.cpu().data.numpy()\n",
        "    pred_seqs = pred_seqs.cpu().data.numpy()\n",
        "    tgt_lens = tgt_lens.cpu().data.numpy()\n",
        "    pred_lens = pred_lens.cpu().data.numpy().astype(int)\n",
        "    \n",
        "    #metrics to compute\n",
        "    precision = 0\n",
        "    recall = 0\n",
        "    acc = 0\n",
        "    #loop: for each prediction, different pred_len and tgt_len make vectorized computation impossible\n",
        "    for i in range(batch_size):\n",
        "        tgt = tgt_seqs[i,1:tgt_lens[i]-1]\n",
        "        pred = pred_seqs[i,1:pred_lens[i]-1]\n",
        "\n",
        "        tp = float((np.isin(pred,tgt)*1).sum())\n",
        "        fp = float((np.isin(pred,tgt,invert=True)*1).sum())\n",
        "        fn = float((np.isin(tgt,pred,invert=True)*1).sum())\n",
        "\n",
        "        #Precision\n",
        "        if (tp + fp != 0.): precision += tp/(tp + fp)\n",
        "        #Recall\n",
        "        if (tp + fn != 0.): recall += tp/(tp + fn)\n",
        "        #Acc\n",
        "        acc += (fp==0. and fn==0.) * 1.\n",
        "\n",
        "    #average values\n",
        "    precision /= batch_size\n",
        "    recall /= batch_size\n",
        "    acc /= batch_size\n",
        "    \n",
        "    if precision + recall != 0.:\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "    else:\n",
        "        f1 = 0.\n",
        "\n",
        "    return acc,f1,precision,recall\n",
        "\n",
        "def get_topK_metrics(tgt_seqs,topk_sequence,tgt_lens,topk_length):\n",
        "    k = topk_length.size(1)\n",
        "    batch_size = tgt_seqs.size(0)\n",
        "    #get numpy arrays\n",
        "    tgt_seqs = tgt_seqs.cpu().data.numpy()    \n",
        "    topk_sequence = topk_sequence.cpu().data.numpy()\n",
        "    topk_length = topk_length.cpu().data.numpy()\n",
        "    \n",
        "    #metrics to compute\n",
        "    top1_f1 = 0\n",
        "    top1_acc = 0\n",
        "    topK_acc = 0\n",
        "    topK_f1 = 0\n",
        "    #loop: for each prediction, different pred_len and tgt_len make vectorized computation impossible\n",
        "    for i in range(batch_size):\n",
        "        tgt = tgt_seqs[i,1:tgt_lens[i].item()-1]\n",
        "        best_acc = 0\n",
        "        best_f1 = 0\n",
        "        for j in range(k):\n",
        "            pred = topk_sequence[i,j,1:topk_length[i,j]-1]\n",
        "\n",
        "            # print(pred)\n",
        "            # print(tgt)\n",
        "            \n",
        "            tp = float((np.isin(pred,tgt)*1).sum())\n",
        "            fp = float((np.isin(pred,tgt,invert=True)*1).sum())\n",
        "            fn = float((np.isin(tgt,pred,invert=True)*1).sum())\n",
        "\n",
        "            #Precision\n",
        "            if (tp + fp != 0.): \n",
        "              precision = tp/(tp + fp)\n",
        "            else: \n",
        "              precision = 0\n",
        "            #Recall\n",
        "            if (tp + fn != 0.): \n",
        "              recall = tp/(tp + fn)\n",
        "            else: \n",
        "              recall = 0\n",
        "            #Acc\n",
        "            acc = (fp==0. and fn==0.) * 1.\n",
        "            #F1\n",
        "            if precision + recall != 0.:\n",
        "                f1 = 2 * precision * recall / (precision + recall)\n",
        "            else:\n",
        "                f1 = 0.\n",
        "            \n",
        "            #record top1 value\n",
        "            if j==0:\n",
        "                top1_acc += acc\n",
        "                top1_f1 += f1\n",
        "\n",
        "            #keep best of K values\n",
        "            if f1>best_f1:\n",
        "                best_f1 = f1\n",
        "            if acc>best_acc:\n",
        "                best_acc = acc\n",
        "\n",
        "        #add best values to topK metrics\n",
        "        topK_acc += best_acc\n",
        "        topK_f1 += best_f1\n",
        "            \n",
        "\n",
        "    #average values\n",
        "    top1_acc /= batch_size\n",
        "    top1_f1 /= batch_size\n",
        "    topK_acc /= batch_size\n",
        "    topK_f1 /= batch_size\n",
        "    return top1_acc,top1_f1,topK_acc,topK_f1\n",
        "\n",
        "def evaluate_full_dataset(val_dataloader,model):\n",
        "    val_dataloader.create_batches()\n",
        "    total_top1_acc = 0\n",
        "    total_top1_f1 = 0\n",
        "    total_topK_acc = 0\n",
        "    total_topK_f1 = 0\n",
        "    nb_eval = len(val_dataloader)\n",
        "    for batch in tqdm(val_dataloader.batches):\n",
        "        topk_sequence,topk_length,tgt_seqs,tgt_lens,output_prob,decoded_sequences,_ = model.evaluate(batch)\n",
        "\n",
        "        top1_acc,top1_f1,topK_acc,topK_f1 = get_topK_metrics(tgt_seqs,topk_sequence,tgt_lens,topk_length)\n",
        "\n",
        "        total_top1_acc += top1_acc\n",
        "        total_top1_f1 += top1_f1\n",
        "        total_topK_acc += topK_acc\n",
        "        total_topK_f1 += topK_f1\n",
        "\n",
        "    #avg values\n",
        "    total_top1_acc /= nb_eval\n",
        "    total_top1_f1 /= nb_eval\n",
        "    total_topK_acc /= nb_eval\n",
        "    total_topK_f1 /= nb_eval\n",
        "\n",
        "    \n",
        "    return total_top1_acc,total_top1_f1,total_topK_acc,total_topK_f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYFpNwjZFz9v"
      },
      "source": [
        "## Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lELtmHvvr1KH"
      },
      "outputs": [],
      "source": [
        "def train_and_validate(model, train_dataloader, val_dataloader, device, config):\n",
        "    \"\"\"\n",
        "    train a model on the given data as loaders.\n",
        "    Inputs: please refer bellow, to the argparse arguments.\n",
        "    \"\"\"\n",
        "    printc(\"\\n----- STARTING TRAINING -----\")\n",
        "\n",
        "    losses = []\n",
        "    val_top1_accuracies = []\n",
        "    val_top1_f1_scores = []\n",
        "    val_top5_accuracies = []\n",
        "    val_top5_f1_scores = []\n",
        "    best_topK_f1_score = 0\n",
        "\n",
        "    n_samples = config.print_every_k_batch * config.batch_size\n",
        "    model.initialize_scheduler(len(train_dataloader.dataset))\n",
        "    for epoch in range(config.epochs):\n",
        "        print(\"> EPOCH\", epoch)\n",
        "        model.train()\n",
        "        epoch_loss, k_batch_loss = 0, 0\n",
        "        epoch_start_time, k_batch_start_time = time(), time()\n",
        "        train_dataloader.create_batches()\n",
        "        #Training loop\n",
        "        for i, batch in enumerate(train_dataloader.batches):\n",
        "\n",
        "            loss, outputs = model.step(batch)\n",
        "\n",
        "            epoch_loss += loss.item()\n",
        "            k_batch_loss += loss.item()\n",
        "\n",
        "            if (i+1) % config.print_every_k_batch == 0:\n",
        "                average_loss = k_batch_loss / n_samples\n",
        "                print(f'    [{i+1-config.print_every_k_batch}-{i+1}]  -  Average loss: {average_loss:.3f}  -  Time elapsed: {pretty_time(time()-k_batch_start_time)}')\n",
        "                k_batch_loss = 0\n",
        "                k_batch_start_time = time()\n",
        "\n",
        "            \n",
        "        #End of epoch\n",
        "        printc(\"-----  Ended Train Epoch ---- Start of validation metrics computation  -----\\n\")\n",
        "        val_top1_acc,val_top1_f1,val_topK_acc,val_topK_f1= evaluate_full_dataset(val_dataloader,model)\n",
        "        print('\\n' + '='*100)\n",
        "        print('Training log:')\n",
        "        print('- Epoch: {}/{}'.format(epoch, config.epochs))\n",
        "        print('- Train loss: {}'.format(epoch_loss/len(train_dataloader.dataset)))\n",
        "        print('- Val Top-1 Accuracy: {}'.format(val_top1_acc))\n",
        "        print('- Val Top-1 F1 Score: {}'.format(val_top1_f1))\n",
        "        print('- Val Top-K Accuracy: {}'.format(val_topK_acc))\n",
        "        print('- Val Top-K F1 Score: {}'.format(val_topK_f1))\n",
        "        print('='*100 + '\\n')\n",
        "        if best_topK_f1_score < val_topK_f1:\n",
        "            best_topK_f1_score = val_topK_f1\n",
        "            #run_number is set when doing hyper parameter optimization\n",
        "            checkpoint_path = os.path.join(config.path_result,'checkpoint_small.pth')\n",
        "            checkpoint = {\n",
        "                'model': model.state_dict(),\n",
        "                'epoch': epoch,\n",
        "                'best_topK_f1_score': best_topK_f1_score,\n",
        "                'tokenizer': model.tokenizer,\n",
        "                'optimizer': model.optimizer.state_dict(),\n",
        "                'scheduler': model.scheduler.state_dict()\n",
        "            }\n",
        "            torch.save(checkpoint,checkpoint_path)\n",
        "            \n",
        "            print('\\n' + '='*100)\n",
        "            print('Saved checkpoint to \"{}\".'.format(checkpoint_path))\n",
        "            print('Best top 5 F1-score value: ', best_topK_f1_score)\n",
        "            print('='*100 + '\\n')\n",
        "\n",
        "        losses.append(epoch_loss/len(train_dataloader))\n",
        "        val_top1_accuracies.append(val_top1_acc)\n",
        "        val_top1_f1_scores.append(val_top1_f1)\n",
        "        val_top5_accuracies.append(val_topK_acc)\n",
        "        val_top5_f1_scores.append(val_topK_f1)\n",
        "        \n",
        "        model.scheduler.step()\n",
        "\n",
        "    \n",
        "    printc(\"-----  Ended Training  -----\\n\")\n",
        "\n",
        "    print(\"Saving losses...\")\n",
        "    save_json(config.path_result, \"losses\", { \"train\": losses })\n",
        "    print(\"Saving validation metrics\")\n",
        "    save_json(config.path_result, \"eval_metrics\", { \"acc_1\": val_top1_accuracies, \"f1_score_1\": val_top1_f1_scores,\n",
        "                                            \"acc_5\":  val_top5_accuracies,\"f1_score_5\":  val_top5_f1_scores})\n",
        "    epochs_realized = len(losses)\n",
        "    #plot loss\n",
        "    plt.plot(range(1, epochs_realized+1), losses)\n",
        "    plt.legend([\"Train loss\"])\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(\"Loss evolution\")\n",
        "    # plt.savefig(os.path.join(config.path_result, \"loss.png\"))\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "    #plot eval data\n",
        "    plt.plot(range(1, epochs_realized+1), val_top5_accuracies)\n",
        "    plt.legend([\"Evaluation Top5 F1-accuracies\"])\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Top5 F1-score\")\n",
        "    plt.title(\"Top5 F1-score Evolution\")\n",
        "    # plt.savefig(os.path.join(config.path_result, \"eval_f1_score.png\"))\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "    print(\"[DONE]\")\n",
        "\n",
        "    return best_topK_f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaCvOiZoHi2j"
      },
      "source": [
        "## Run Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d48fb7371e344b639065c4eecbdc3f84",
            "ba08760c15374a11bf8e355d4a368d6e",
            "dc93b2c2e8b241abb64738112c67daa8",
            "5cf15ff374044ca3849809e1b712f8a6",
            "05b8800f24054caaae891542c5f22585",
            "d0740d5e3a2f463cad3d923a852e0f7b",
            "606e974774bf491faa80f0594a31f891",
            "96acb4b8c3484ea18e68e100cc691cf5",
            "c0fdb566540842a799f876bdb0d76685",
            "33880c7b95234e8280572f2751d7bfcf",
            "407ad57804334f11b1af75d5c024d6c7",
            "c21a6902b3d44c6bb9e66b3dc6e44bfa",
            "965f64f465b642118e59bc8e38bc2258",
            "0f39fd6ff9664302b2433dbf1707c58d",
            "be97a599ff99428fbbf27fde889e2352",
            "3492e382c3334c168768b275ecbb374a",
            "1ec7bdea25f140f8b97913a114fb6e93",
            "55e10b21892540df85a94e069b719fd6",
            "6246da18dd694546957fe889b3c9586c",
            "deb0f915186b4d58ad79d11b63719141",
            "80b0a05094eb4523a785482a7e1c8d0f",
            "0bd25d26c0c94a96957fe5f313521a79",
            "996a44f0fcc74aa591a7dac4662d8079",
            "29913220601d4f1c917dd08a00ef2ab8",
            "1dca93ead0524d7db3958c16a8fac456",
            "dc54c049a6504bf48a64f791a68107a3",
            "1079edb3494a480a9c1046415db837a0",
            "55a260476d9a410a83af815ad63213da",
            "d63c537eccd540b7b52794219d2e6f77",
            "982d923c0c8749298a9de01f50d1e98f",
            "6ec714aa6b0c45dd96827f7a364f76dd",
            "33b3099dfc8c4ddf92266e60752f421b",
            "56f3ee334db54236a4423156945d7ea6",
            "10b1bfceddd2488db5ea3f3e939b7316"
          ]
        },
        "id": "K_dC2xCE3tGO",
        "outputId": "7e66df76-b8bb-43bc-9910-4b9010c89641"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[94m\n",
            "----- STARTING TRAINING -----\u001b[0m\n",
            "> EPOCH 0\n",
            "    [0-256]  -  Average loss: 0.974  -  Time elapsed: 0m55s\n",
            "    [256-512]  -  Average loss: 0.974  -  Time elapsed: 0m54s\n",
            "    [512-768]  -  Average loss: 0.978  -  Time elapsed: 0m53s\n",
            "    [768-1024]  -  Average loss: 0.970  -  Time elapsed: 0m55s\n",
            "    [1024-1280]  -  Average loss: 0.977  -  Time elapsed: 0m54s\n",
            "    [1280-1536]  -  Average loss: 0.975  -  Time elapsed: 0m54s\n",
            "    [1536-1792]  -  Average loss: 0.979  -  Time elapsed: 0m56s\n",
            "    [1792-2048]  -  Average loss: 0.973  -  Time elapsed: 0m54s\n",
            "    [2048-2304]  -  Average loss: 0.978  -  Time elapsed: 0m55s\n",
            "    [2304-2560]  -  Average loss: 0.973  -  Time elapsed: 0m55s\n",
            "    [2560-2816]  -  Average loss: 0.972  -  Time elapsed: 0m53s\n",
            "    [2816-3072]  -  Average loss: 0.974  -  Time elapsed: 0m54s\n",
            "    [3072-3328]  -  Average loss: 0.978  -  Time elapsed: 0m55s\n",
            "    [3328-3584]  -  Average loss: 0.971  -  Time elapsed: 0m53s\n",
            "    [3584-3840]  -  Average loss: 0.972  -  Time elapsed: 0m54s\n",
            "    [3840-4096]  -  Average loss: 0.970  -  Time elapsed: 0m54s\n",
            "    [4096-4352]  -  Average loss: 0.976  -  Time elapsed: 0m54s\n",
            "    [4352-4608]  -  Average loss: 0.975  -  Time elapsed: 0m55s\n",
            "    [4608-4864]  -  Average loss: 0.976  -  Time elapsed: 0m55s\n",
            "    [4864-5120]  -  Average loss: 0.971  -  Time elapsed: 0m54s\n",
            "    [5120-5376]  -  Average loss: 0.979  -  Time elapsed: 0m53s\n",
            "    [5376-5632]  -  Average loss: 0.978  -  Time elapsed: 0m54s\n",
            "    [5632-5888]  -  Average loss: 0.977  -  Time elapsed: 0m55s\n",
            "    [5888-6144]  -  Average loss: 0.972  -  Time elapsed: 0m55s\n",
            "    [6144-6400]  -  Average loss: 0.972  -  Time elapsed: 0m54s\n",
            "    [6400-6656]  -  Average loss: 0.973  -  Time elapsed: 0m56s\n",
            "    [6656-6912]  -  Average loss: 0.973  -  Time elapsed: 0m54s\n",
            "    [6912-7168]  -  Average loss: 0.976  -  Time elapsed: 0m55s\n",
            "    [7168-7424]  -  Average loss: 0.971  -  Time elapsed: 0m53s\n",
            "    [7424-7680]  -  Average loss: 0.972  -  Time elapsed: 0m55s\n",
            "    [7680-7936]  -  Average loss: 0.978  -  Time elapsed: 0m54s\n",
            "    [7936-8192]  -  Average loss: 0.973  -  Time elapsed: 0m55s\n",
            "    [8192-8448]  -  Average loss: 0.974  -  Time elapsed: 0m55s\n",
            "    [8448-8704]  -  Average loss: 0.974  -  Time elapsed: 0m55s\n",
            "    [8704-8960]  -  Average loss: 0.973  -  Time elapsed: 0m53s\n",
            "    [8960-9216]  -  Average loss: 0.973  -  Time elapsed: 0m56s\n",
            "    [9216-9472]  -  Average loss: 0.973  -  Time elapsed: 0m54s\n",
            "    [9472-9728]  -  Average loss: 0.972  -  Time elapsed: 0m54s\n",
            "    [9728-9984]  -  Average loss: 0.969  -  Time elapsed: 0m54s\n",
            "    [9984-10240]  -  Average loss: 0.983  -  Time elapsed: 0m53s\n",
            "    [10240-10496]  -  Average loss: 0.972  -  Time elapsed: 0m55s\n",
            "    [10496-10752]  -  Average loss: 0.976  -  Time elapsed: 0m54s\n",
            "    [10752-11008]  -  Average loss: 0.978  -  Time elapsed: 0m53s\n",
            "    [11008-11264]  -  Average loss: 0.972  -  Time elapsed: 0m56s\n",
            "    [11264-11520]  -  Average loss: 0.973  -  Time elapsed: 0m52s\n",
            "    [11520-11776]  -  Average loss: 0.972  -  Time elapsed: 0m54s\n",
            "    [11776-12032]  -  Average loss: 0.976  -  Time elapsed: 0m53s\n",
            "    [12032-12288]  -  Average loss: 0.975  -  Time elapsed: 0m55s\n",
            "    [12288-12544]  -  Average loss: 0.973  -  Time elapsed: 0m54s\n",
            "    [12544-12800]  -  Average loss: 0.975  -  Time elapsed: 0m56s\n",
            "    [12800-13056]  -  Average loss: 0.972  -  Time elapsed: 0m55s\n",
            "    [13056-13312]  -  Average loss: 0.970  -  Time elapsed: 0m52s\n",
            "    [13312-13568]  -  Average loss: 0.973  -  Time elapsed: 0m55s\n",
            "    [13568-13824]  -  Average loss: 0.973  -  Time elapsed: 0m55s\n",
            "    [13824-14080]  -  Average loss: 0.974  -  Time elapsed: 0m54s\n",
            "    [14080-14336]  -  Average loss: 0.970  -  Time elapsed: 0m53s\n",
            "    [14336-14592]  -  Average loss: 0.981  -  Time elapsed: 0m54s\n",
            "    [14592-14848]  -  Average loss: 0.976  -  Time elapsed: 0m54s\n",
            "    [14848-15104]  -  Average loss: 0.972  -  Time elapsed: 0m56s\n",
            "    [15104-15360]  -  Average loss: 0.979  -  Time elapsed: 0m52s\n",
            "    [15360-15616]  -  Average loss: 0.972  -  Time elapsed: 0m56s\n",
            "    [15616-15872]  -  Average loss: 0.976  -  Time elapsed: 0m55s\n",
            "    [15872-16128]  -  Average loss: 0.976  -  Time elapsed: 0m54s\n",
            "    [16128-16384]  -  Average loss: 0.968  -  Time elapsed: 0m53s\n",
            "    [16384-16640]  -  Average loss: 0.975  -  Time elapsed: 0m54s\n",
            "    [16640-16896]  -  Average loss: 0.978  -  Time elapsed: 0m55s\n",
            "    [16896-17152]  -  Average loss: 0.974  -  Time elapsed: 0m53s\n",
            "    [17152-17408]  -  Average loss: 0.974  -  Time elapsed: 0m55s\n",
            "    [17408-17664]  -  Average loss: 0.978  -  Time elapsed: 0m55s\n",
            "    [17664-17920]  -  Average loss: 0.970  -  Time elapsed: 0m54s\n",
            "    [17920-18176]  -  Average loss: 0.979  -  Time elapsed: 0m54s\n",
            "    [18176-18432]  -  Average loss: 0.978  -  Time elapsed: 0m53s\n",
            "    [18432-18688]  -  Average loss: 0.969  -  Time elapsed: 0m55s\n",
            "    [18688-18944]  -  Average loss: 0.970  -  Time elapsed: 0m54s\n",
            "    [18944-19200]  -  Average loss: 0.976  -  Time elapsed: 0m54s\n",
            "    [19200-19456]  -  Average loss: 0.977  -  Time elapsed: 0m55s\n",
            "    [19456-19712]  -  Average loss: 0.977  -  Time elapsed: 0m54s\n",
            "    [19712-19968]  -  Average loss: 0.973  -  Time elapsed: 0m53s\n",
            "    [19968-20224]  -  Average loss: 0.972  -  Time elapsed: 0m54s\n",
            "    [20224-20480]  -  Average loss: 0.974  -  Time elapsed: 0m55s\n",
            "    [20480-20736]  -  Average loss: 0.973  -  Time elapsed: 0m54s\n",
            "    [20736-20992]  -  Average loss: 0.977  -  Time elapsed: 0m54s\n",
            "    [20992-21248]  -  Average loss: 0.973  -  Time elapsed: 0m54s\n",
            "    [21248-21504]  -  Average loss: 0.975  -  Time elapsed: 0m55s\n",
            "    [21504-21760]  -  Average loss: 0.976  -  Time elapsed: 0m54s\n",
            "    [21760-22016]  -  Average loss: 0.972  -  Time elapsed: 0m55s\n",
            "    [22016-22272]  -  Average loss: 0.972  -  Time elapsed: 0m54s\n",
            "    [22272-22528]  -  Average loss: 0.974  -  Time elapsed: 0m55s\n",
            "    [22528-22784]  -  Average loss: 0.978  -  Time elapsed: 0m55s\n",
            "    [22784-23040]  -  Average loss: 0.974  -  Time elapsed: 0m54s\n",
            "    [23040-23296]  -  Average loss: 0.970  -  Time elapsed: 0m55s\n",
            "    [23296-23552]  -  Average loss: 0.975  -  Time elapsed: 0m55s\n",
            "\u001b[94m-----  Ended Train Epoch ---- Start of validation metrics computation  -----\n",
            "\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d48fb7371e344b639065c4eecbdc3f84",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================================================================================================\n",
            "Training log:\n",
            "- Epoch: 0/10\n",
            "- Train loss: 0.9742503425196894\n",
            "- Val Top-1 Accuracy: 0.0\n",
            "- Val Top-1 F1 Score: 0.0006640308191403081\n",
            "- Val Top-K Accuracy: 0.0\n",
            "- Val Top-K F1 Score: 0.0013407339821573398\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "Saved checkpoint to \"checkpoint_small.pth\".\n",
            "Best top 5 F1-score value:  0.0013407339821573398\n",
            "====================================================================================================\n",
            "\n",
            "> EPOCH 1\n",
            "    [0-256]  -  Average loss: 0.268  -  Time elapsed: 0m57s\n",
            "    [256-512]  -  Average loss: 0.189  -  Time elapsed: 0m55s\n",
            "    [512-768]  -  Average loss: 0.177  -  Time elapsed: 0m52s\n",
            "    [768-1024]  -  Average loss: 0.170  -  Time elapsed: 0m54s\n",
            "    [1024-1280]  -  Average loss: 0.164  -  Time elapsed: 0m56s\n",
            "    [1280-1536]  -  Average loss: 0.157  -  Time elapsed: 0m53s\n",
            "    [1536-1792]  -  Average loss: 0.159  -  Time elapsed: 0m56s\n",
            "    [1792-2048]  -  Average loss: 0.150  -  Time elapsed: 0m54s\n",
            "    [2048-2304]  -  Average loss: 0.147  -  Time elapsed: 0m54s\n",
            "    [2304-2560]  -  Average loss: 0.146  -  Time elapsed: 0m54s\n",
            "    [2560-2816]  -  Average loss: 0.145  -  Time elapsed: 0m54s\n",
            "    [2816-3072]  -  Average loss: 0.142  -  Time elapsed: 0m53s\n",
            "    [3072-3328]  -  Average loss: 0.140  -  Time elapsed: 0m55s\n",
            "    [3328-3584]  -  Average loss: 0.138  -  Time elapsed: 0m55s\n",
            "    [3584-3840]  -  Average loss: 0.140  -  Time elapsed: 0m53s\n",
            "    [3840-4096]  -  Average loss: 0.139  -  Time elapsed: 0m55s\n",
            "    [4096-4352]  -  Average loss: 0.133  -  Time elapsed: 0m55s\n",
            "    [4352-4608]  -  Average loss: 0.137  -  Time elapsed: 0m54s\n",
            "    [4608-4864]  -  Average loss: 0.137  -  Time elapsed: 0m55s\n",
            "    [4864-5120]  -  Average loss: 0.134  -  Time elapsed: 0m55s\n",
            "    [5120-5376]  -  Average loss: 0.132  -  Time elapsed: 0m54s\n",
            "    [5376-5632]  -  Average loss: 0.136  -  Time elapsed: 0m55s\n",
            "    [5632-5888]  -  Average loss: 0.131  -  Time elapsed: 0m55s\n",
            "    [5888-6144]  -  Average loss: 0.132  -  Time elapsed: 0m53s\n",
            "    [6144-6400]  -  Average loss: 0.134  -  Time elapsed: 0m55s\n",
            "    [6400-6656]  -  Average loss: 0.133  -  Time elapsed: 0m55s\n",
            "    [6656-6912]  -  Average loss: 0.133  -  Time elapsed: 0m53s\n",
            "    [6912-7168]  -  Average loss: 0.130  -  Time elapsed: 0m55s\n",
            "    [7168-7424]  -  Average loss: 0.129  -  Time elapsed: 0m54s\n",
            "    [7424-7680]  -  Average loss: 0.131  -  Time elapsed: 0m54s\n",
            "    [7680-7936]  -  Average loss: 0.127  -  Time elapsed: 0m54s\n",
            "    [7936-8192]  -  Average loss: 0.129  -  Time elapsed: 0m53s\n",
            "    [8192-8448]  -  Average loss: 0.126  -  Time elapsed: 0m54s\n",
            "    [8448-8704]  -  Average loss: 0.129  -  Time elapsed: 0m55s\n",
            "    [8704-8960]  -  Average loss: 0.129  -  Time elapsed: 0m54s\n",
            "    [8960-9216]  -  Average loss: 0.125  -  Time elapsed: 0m53s\n",
            "    [9216-9472]  -  Average loss: 0.126  -  Time elapsed: 0m55s\n",
            "    [9472-9728]  -  Average loss: 0.126  -  Time elapsed: 0m55s\n",
            "    [9728-9984]  -  Average loss: 0.127  -  Time elapsed: 0m55s\n",
            "    [9984-10240]  -  Average loss: 0.123  -  Time elapsed: 0m54s\n",
            "    [10240-10496]  -  Average loss: 0.122  -  Time elapsed: 0m54s\n",
            "    [10496-10752]  -  Average loss: 0.123  -  Time elapsed: 0m55s\n",
            "    [10752-11008]  -  Average loss: 0.119  -  Time elapsed: 0m54s\n",
            "    [11008-11264]  -  Average loss: 0.122  -  Time elapsed: 0m54s\n",
            "    [11264-11520]  -  Average loss: 0.122  -  Time elapsed: 0m54s\n",
            "    [11520-11776]  -  Average loss: 0.124  -  Time elapsed: 0m55s\n",
            "    [11776-12032]  -  Average loss: 0.120  -  Time elapsed: 0m55s\n",
            "    [12032-12288]  -  Average loss: 0.122  -  Time elapsed: 0m53s\n",
            "    [12288-12544]  -  Average loss: 0.118  -  Time elapsed: 0m53s\n",
            "    [12544-12800]  -  Average loss: 0.117  -  Time elapsed: 0m55s\n",
            "    [12800-13056]  -  Average loss: 0.120  -  Time elapsed: 0m54s\n",
            "    [13056-13312]  -  Average loss: 0.117  -  Time elapsed: 0m53s\n",
            "    [13312-13568]  -  Average loss: 0.119  -  Time elapsed: 0m53s\n",
            "    [13568-13824]  -  Average loss: 0.120  -  Time elapsed: 0m53s\n",
            "    [13824-14080]  -  Average loss: 0.116  -  Time elapsed: 0m55s\n",
            "    [14080-14336]  -  Average loss: 0.119  -  Time elapsed: 0m55s\n",
            "    [14336-14592]  -  Average loss: 0.118  -  Time elapsed: 0m54s\n",
            "    [14592-14848]  -  Average loss: 0.119  -  Time elapsed: 0m54s\n",
            "    [14848-15104]  -  Average loss: 0.118  -  Time elapsed: 0m54s\n",
            "    [15104-15360]  -  Average loss: 0.120  -  Time elapsed: 0m56s\n",
            "    [15360-15616]  -  Average loss: 0.117  -  Time elapsed: 0m54s\n",
            "    [15616-15872]  -  Average loss: 0.117  -  Time elapsed: 0m53s\n",
            "    [15872-16128]  -  Average loss: 0.119  -  Time elapsed: 0m55s\n",
            "    [16128-16384]  -  Average loss: 0.118  -  Time elapsed: 0m55s\n",
            "    [16384-16640]  -  Average loss: 0.118  -  Time elapsed: 0m52s\n",
            "    [16640-16896]  -  Average loss: 0.118  -  Time elapsed: 0m56s\n",
            "    [16896-17152]  -  Average loss: 0.117  -  Time elapsed: 0m54s\n",
            "    [17152-17408]  -  Average loss: 0.119  -  Time elapsed: 0m54s\n",
            "    [17408-17664]  -  Average loss: 0.116  -  Time elapsed: 0m55s\n",
            "    [17664-17920]  -  Average loss: 0.116  -  Time elapsed: 0m54s\n",
            "    [17920-18176]  -  Average loss: 0.116  -  Time elapsed: 0m54s\n",
            "    [18176-18432]  -  Average loss: 0.117  -  Time elapsed: 0m55s\n",
            "    [18432-18688]  -  Average loss: 0.116  -  Time elapsed: 0m54s\n",
            "    [18688-18944]  -  Average loss: 0.115  -  Time elapsed: 0m54s\n",
            "    [18944-19200]  -  Average loss: 0.118  -  Time elapsed: 0m55s\n",
            "    [19200-19456]  -  Average loss: 0.116  -  Time elapsed: 0m54s\n",
            "    [19456-19712]  -  Average loss: 0.115  -  Time elapsed: 0m54s\n",
            "    [19712-19968]  -  Average loss: 0.115  -  Time elapsed: 0m54s\n",
            "    [19968-20224]  -  Average loss: 0.119  -  Time elapsed: 0m55s\n",
            "    [20224-20480]  -  Average loss: 0.115  -  Time elapsed: 0m54s\n",
            "    [20480-20736]  -  Average loss: 0.116  -  Time elapsed: 0m54s\n",
            "    [20736-20992]  -  Average loss: 0.115  -  Time elapsed: 0m54s\n",
            "    [20992-21248]  -  Average loss: 0.114  -  Time elapsed: 0m56s\n",
            "    [21248-21504]  -  Average loss: 0.114  -  Time elapsed: 0m55s\n",
            "    [21504-21760]  -  Average loss: 0.115  -  Time elapsed: 0m55s\n",
            "    [21760-22016]  -  Average loss: 0.112  -  Time elapsed: 0m56s\n",
            "    [22016-22272]  -  Average loss: 0.113  -  Time elapsed: 0m54s\n",
            "    [22272-22528]  -  Average loss: 0.112  -  Time elapsed: 0m54s\n",
            "    [22528-22784]  -  Average loss: 0.114  -  Time elapsed: 0m53s\n",
            "    [22784-23040]  -  Average loss: 0.112  -  Time elapsed: 0m55s\n",
            "    [23040-23296]  -  Average loss: 0.113  -  Time elapsed: 0m53s\n",
            "    [23296-23552]  -  Average loss: 0.114  -  Time elapsed: 0m55s\n",
            "\u001b[94m-----  Ended Train Epoch ---- Start of validation metrics computation  -----\n",
            "\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c21a6902b3d44c6bb9e66b3dc6e44bfa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================================================================================================\n",
            "Training log:\n",
            "- Epoch: 1/10\n",
            "- Train loss: 0.12818346985372714\n",
            "- Val Top-1 Accuracy: 0.10456204379562044\n",
            "- Val Top-1 F1 Score: 0.2826011326467532\n",
            "- Val Top-K Accuracy: 0.1697992700729927\n",
            "- Val Top-K F1 Score: 0.39677036011433836\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "Saved checkpoint to \"checkpoint_small.pth\".\n",
            "Best top 5 F1-score value:  0.39677036011433836\n",
            "====================================================================================================\n",
            "\n",
            "> EPOCH 2\n",
            "    [0-256]  -  Average loss: 0.112  -  Time elapsed: 0m55s\n",
            "    [256-512]  -  Average loss: 0.110  -  Time elapsed: 0m54s\n",
            "    [512-768]  -  Average loss: 0.108  -  Time elapsed: 0m54s\n",
            "    [768-1024]  -  Average loss: 0.109  -  Time elapsed: 0m53s\n",
            "    [1024-1280]  -  Average loss: 0.109  -  Time elapsed: 0m54s\n",
            "    [1280-1536]  -  Average loss: 0.109  -  Time elapsed: 0m55s\n",
            "    [1536-1792]  -  Average loss: 0.114  -  Time elapsed: 0m54s\n",
            "    [1792-2048]  -  Average loss: 0.108  -  Time elapsed: 0m56s\n",
            "    [2048-2304]  -  Average loss: 0.110  -  Time elapsed: 0m53s\n",
            "    [2304-2560]  -  Average loss: 0.111  -  Time elapsed: 0m54s\n",
            "    [2560-2816]  -  Average loss: 0.108  -  Time elapsed: 0m54s\n",
            "    [2816-3072]  -  Average loss: 0.109  -  Time elapsed: 0m54s\n",
            "    [3072-3328]  -  Average loss: 0.107  -  Time elapsed: 0m55s\n",
            "    [3328-3584]  -  Average loss: 0.110  -  Time elapsed: 0m52s\n",
            "    [3584-3840]  -  Average loss: 0.107  -  Time elapsed: 0m56s\n",
            "    [3840-4096]  -  Average loss: 0.109  -  Time elapsed: 0m54s\n",
            "    [4096-4352]  -  Average loss: 0.110  -  Time elapsed: 0m53s\n",
            "    [4352-4608]  -  Average loss: 0.108  -  Time elapsed: 0m54s\n",
            "    [4608-4864]  -  Average loss: 0.109  -  Time elapsed: 0m53s\n",
            "    [4864-5120]  -  Average loss: 0.107  -  Time elapsed: 0m55s\n",
            "    [5120-5376]  -  Average loss: 0.110  -  Time elapsed: 0m53s\n",
            "    [5376-5632]  -  Average loss: 0.110  -  Time elapsed: 0m55s\n",
            "    [5632-5888]  -  Average loss: 0.109  -  Time elapsed: 0m55s\n",
            "    [5888-6144]  -  Average loss: 0.106  -  Time elapsed: 0m53s\n",
            "    [6144-6400]  -  Average loss: 0.110  -  Time elapsed: 0m55s\n",
            "    [6400-6656]  -  Average loss: 0.106  -  Time elapsed: 0m54s\n",
            "    [6656-6912]  -  Average loss: 0.108  -  Time elapsed: 0m55s\n",
            "    [6912-7168]  -  Average loss: 0.109  -  Time elapsed: 0m55s\n",
            "    [7168-7424]  -  Average loss: 0.110  -  Time elapsed: 0m55s\n",
            "    [7424-7680]  -  Average loss: 0.107  -  Time elapsed: 0m53s\n",
            "    [7680-7936]  -  Average loss: 0.107  -  Time elapsed: 0m55s\n",
            "    [7936-8192]  -  Average loss: 0.107  -  Time elapsed: 0m55s\n",
            "    [8192-8448]  -  Average loss: 0.106  -  Time elapsed: 0m54s\n",
            "    [8448-8704]  -  Average loss: 0.109  -  Time elapsed: 0m55s\n",
            "    [8704-8960]  -  Average loss: 0.106  -  Time elapsed: 0m53s\n",
            "    [8960-9216]  -  Average loss: 0.109  -  Time elapsed: 0m55s\n",
            "    [9216-9472]  -  Average loss: 0.104  -  Time elapsed: 0m53s\n",
            "    [9472-9728]  -  Average loss: 0.105  -  Time elapsed: 0m55s\n",
            "    [9728-9984]  -  Average loss: 0.105  -  Time elapsed: 0m55s\n",
            "    [9984-10240]  -  Average loss: 0.105  -  Time elapsed: 0m55s\n",
            "    [10240-10496]  -  Average loss: 0.104  -  Time elapsed: 0m54s\n",
            "    [10496-10752]  -  Average loss: 0.104  -  Time elapsed: 0m55s\n",
            "    [10752-11008]  -  Average loss: 0.105  -  Time elapsed: 0m54s\n",
            "    [11008-11264]  -  Average loss: 0.103  -  Time elapsed: 0m54s\n",
            "    [11264-11520]  -  Average loss: 0.104  -  Time elapsed: 0m54s\n",
            "    [11520-11776]  -  Average loss: 0.103  -  Time elapsed: 0m54s\n",
            "    [11776-12032]  -  Average loss: 0.104  -  Time elapsed: 0m54s\n",
            "    [12032-12288]  -  Average loss: 0.104  -  Time elapsed: 0m54s\n",
            "    [12288-12544]  -  Average loss: 0.104  -  Time elapsed: 0m56s\n",
            "    [12544-12800]  -  Average loss: 0.105  -  Time elapsed: 0m54s\n",
            "    [12800-13056]  -  Average loss: 0.104  -  Time elapsed: 0m54s\n",
            "    [13056-13312]  -  Average loss: 0.105  -  Time elapsed: 0m54s\n",
            "    [13312-13568]  -  Average loss: 0.106  -  Time elapsed: 0m53s\n",
            "    [13568-13824]  -  Average loss: 0.102  -  Time elapsed: 0m55s\n",
            "    [13824-14080]  -  Average loss: 0.105  -  Time elapsed: 0m56s\n",
            "    [14080-14336]  -  Average loss: 0.104  -  Time elapsed: 0m53s\n",
            "    [14336-14592]  -  Average loss: 0.104  -  Time elapsed: 0m54s\n",
            "    [14592-14848]  -  Average loss: 0.105  -  Time elapsed: 0m56s\n",
            "    [14848-15104]  -  Average loss: 0.104  -  Time elapsed: 0m54s\n",
            "    [15104-15360]  -  Average loss: 0.103  -  Time elapsed: 0m52s\n",
            "    [15360-15616]  -  Average loss: 0.104  -  Time elapsed: 0m54s\n",
            "    [15616-15872]  -  Average loss: 0.102  -  Time elapsed: 0m54s\n",
            "    [15872-16128]  -  Average loss: 0.105  -  Time elapsed: 0m55s\n",
            "    [16128-16384]  -  Average loss: 0.103  -  Time elapsed: 0m55s\n",
            "    [16384-16640]  -  Average loss: 0.103  -  Time elapsed: 0m55s\n",
            "    [16640-16896]  -  Average loss: 0.105  -  Time elapsed: 0m54s\n",
            "    [16896-17152]  -  Average loss: 0.103  -  Time elapsed: 0m54s\n",
            "    [17152-17408]  -  Average loss: 0.103  -  Time elapsed: 0m56s\n",
            "    [17408-17664]  -  Average loss: 0.103  -  Time elapsed: 0m55s\n",
            "    [17664-17920]  -  Average loss: 0.102  -  Time elapsed: 0m54s\n",
            "    [17920-18176]  -  Average loss: 0.100  -  Time elapsed: 0m55s\n",
            "    [18176-18432]  -  Average loss: 0.102  -  Time elapsed: 0m53s\n",
            "    [18432-18688]  -  Average loss: 0.100  -  Time elapsed: 0m55s\n",
            "    [18688-18944]  -  Average loss: 0.103  -  Time elapsed: 0m54s\n",
            "    [18944-19200]  -  Average loss: 0.102  -  Time elapsed: 0m55s\n",
            "    [19200-19456]  -  Average loss: 0.102  -  Time elapsed: 0m53s\n",
            "    [19456-19712]  -  Average loss: 0.103  -  Time elapsed: 0m54s\n",
            "    [19712-19968]  -  Average loss: 0.103  -  Time elapsed: 0m53s\n",
            "    [19968-20224]  -  Average loss: 0.100  -  Time elapsed: 0m54s\n",
            "    [20224-20480]  -  Average loss: 0.101  -  Time elapsed: 0m55s\n",
            "    [20480-20736]  -  Average loss: 0.102  -  Time elapsed: 0m54s\n",
            "    [20736-20992]  -  Average loss: 0.101  -  Time elapsed: 0m55s\n",
            "    [20992-21248]  -  Average loss: 0.102  -  Time elapsed: 0m53s\n",
            "    [21248-21504]  -  Average loss: 0.101  -  Time elapsed: 0m56s\n",
            "    [21504-21760]  -  Average loss: 0.102  -  Time elapsed: 0m55s\n",
            "    [21760-22016]  -  Average loss: 0.103  -  Time elapsed: 0m55s\n",
            "    [22016-22272]  -  Average loss: 0.102  -  Time elapsed: 0m54s\n",
            "    [22272-22528]  -  Average loss: 0.105  -  Time elapsed: 0m55s\n",
            "    [22528-22784]  -  Average loss: 0.099  -  Time elapsed: 0m53s\n",
            "    [22784-23040]  -  Average loss: 0.100  -  Time elapsed: 0m55s\n",
            "    [23040-23296]  -  Average loss: 0.104  -  Time elapsed: 0m54s\n",
            "    [23296-23552]  -  Average loss: 0.103  -  Time elapsed: 0m53s\n",
            "\u001b[94m-----  Ended Train Epoch ---- Start of validation metrics computation  -----\n",
            "\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "996a44f0fcc74aa591a7dac4662d8079",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================================================================================================\n",
            "Training log:\n",
            "- Epoch: 2/10\n",
            "- Train loss: 0.10527366878053374\n",
            "- Val Top-1 Accuracy: 0.11815693430656934\n",
            "- Val Top-1 F1 Score: 0.3055652326181522\n",
            "- Val Top-K Accuracy: 0.18895985401459853\n",
            "- Val Top-K F1 Score: 0.42447144805721454\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "Saved checkpoint to \"checkpoint_small.pth\".\n",
            "Best top 5 F1-score value:  0.42447144805721454\n",
            "====================================================================================================\n",
            "\n",
            "> EPOCH 3\n",
            "    [0-256]  -  Average loss: 0.092  -  Time elapsed: 0m55s\n",
            "    [256-512]  -  Average loss: 0.093  -  Time elapsed: 0m54s\n",
            "    [512-768]  -  Average loss: 0.093  -  Time elapsed: 0m55s\n",
            "    [768-1024]  -  Average loss: 0.094  -  Time elapsed: 0m53s\n",
            "    [1024-1280]  -  Average loss: 0.091  -  Time elapsed: 0m56s\n",
            "    [1280-1536]  -  Average loss: 0.092  -  Time elapsed: 0m53s\n",
            "    [1536-1792]  -  Average loss: 0.092  -  Time elapsed: 0m55s\n",
            "    [1792-2048]  -  Average loss: 0.092  -  Time elapsed: 0m53s\n",
            "    [2048-2304]  -  Average loss: 0.091  -  Time elapsed: 0m55s\n",
            "    [2304-2560]  -  Average loss: 0.095  -  Time elapsed: 0m54s\n",
            "    [2560-2816]  -  Average loss: 0.093  -  Time elapsed: 0m54s\n",
            "    [2816-3072]  -  Average loss: 0.095  -  Time elapsed: 0m53s\n",
            "    [3072-3328]  -  Average loss: 0.095  -  Time elapsed: 0m54s\n",
            "    [3328-3584]  -  Average loss: 0.094  -  Time elapsed: 0m55s\n",
            "    [3584-3840]  -  Average loss: 0.093  -  Time elapsed: 0m55s\n",
            "    [3840-4096]  -  Average loss: 0.091  -  Time elapsed: 0m54s\n",
            "    [4096-4352]  -  Average loss: 0.093  -  Time elapsed: 0m54s\n",
            "    [4352-4608]  -  Average loss: 0.092  -  Time elapsed: 0m54s\n",
            "    [4608-4864]  -  Average loss: 0.094  -  Time elapsed: 0m56s\n",
            "    [4864-5120]  -  Average loss: 0.095  -  Time elapsed: 0m54s\n",
            "    [5120-5376]  -  Average loss: 0.094  -  Time elapsed: 0m54s\n",
            "    [5376-5632]  -  Average loss: 0.093  -  Time elapsed: 0m54s\n",
            "    [5632-5888]  -  Average loss: 0.094  -  Time elapsed: 0m55s\n",
            "    [5888-6144]  -  Average loss: 0.094  -  Time elapsed: 0m54s\n",
            "    [6144-6400]  -  Average loss: 0.095  -  Time elapsed: 0m54s\n",
            "    [6400-6656]  -  Average loss: 0.096  -  Time elapsed: 0m54s\n",
            "    [6656-6912]  -  Average loss: 0.095  -  Time elapsed: 0m55s\n",
            "    [6912-7168]  -  Average loss: 0.093  -  Time elapsed: 0m55s\n",
            "    [7168-7424]  -  Average loss: 0.093  -  Time elapsed: 0m53s\n",
            "    [7424-7680]  -  Average loss: 0.094  -  Time elapsed: 0m55s\n",
            "    [7680-7936]  -  Average loss: 0.091  -  Time elapsed: 0m56s\n",
            "    [7936-8192]  -  Average loss: 0.093  -  Time elapsed: 0m54s\n",
            "    [8192-8448]  -  Average loss: 0.094  -  Time elapsed: 0m54s\n",
            "    [8448-8704]  -  Average loss: 0.091  -  Time elapsed: 0m54s\n",
            "    [8704-8960]  -  Average loss: 0.092  -  Time elapsed: 0m54s\n",
            "    [8960-9216]  -  Average loss: 0.094  -  Time elapsed: 0m55s\n",
            "    [9216-9472]  -  Average loss: 0.093  -  Time elapsed: 0m55s\n",
            "    [9472-9728]  -  Average loss: 0.096  -  Time elapsed: 0m54s\n",
            "    [9728-9984]  -  Average loss: 0.092  -  Time elapsed: 0m54s\n",
            "    [9984-10240]  -  Average loss: 0.091  -  Time elapsed: 0m55s\n",
            "    [10240-10496]  -  Average loss: 0.093  -  Time elapsed: 0m56s\n",
            "    [10496-10752]  -  Average loss: 0.092  -  Time elapsed: 0m55s\n",
            "    [10752-11008]  -  Average loss: 0.094  -  Time elapsed: 0m54s\n",
            "    [11008-11264]  -  Average loss: 0.096  -  Time elapsed: 0m55s\n",
            "    [11264-11520]  -  Average loss: 0.094  -  Time elapsed: 0m54s\n",
            "    [11520-11776]  -  Average loss: 0.092  -  Time elapsed: 0m54s\n",
            "    [11776-12032]  -  Average loss: 0.093  -  Time elapsed: 0m55s\n",
            "    [12032-12288]  -  Average loss: 0.094  -  Time elapsed: 0m54s\n",
            "    [12288-12544]  -  Average loss: 0.091  -  Time elapsed: 0m53s\n",
            "    [12544-12800]  -  Average loss: 0.092  -  Time elapsed: 0m55s\n",
            "    [12800-13056]  -  Average loss: 0.095  -  Time elapsed: 0m54s\n",
            "    [13056-13312]  -  Average loss: 0.094  -  Time elapsed: 0m55s\n",
            "    [13312-13568]  -  Average loss: 0.094  -  Time elapsed: 0m54s\n",
            "    [13568-13824]  -  Average loss: 0.091  -  Time elapsed: 0m56s\n",
            "    [13824-14080]  -  Average loss: 0.094  -  Time elapsed: 0m53s\n",
            "    [14080-14336]  -  Average loss: 0.092  -  Time elapsed: 0m52s\n",
            "    [14336-14592]  -  Average loss: 0.091  -  Time elapsed: 0m55s\n",
            "    [14592-14848]  -  Average loss: 0.092  -  Time elapsed: 0m55s\n",
            "    [14848-15104]  -  Average loss: 0.092  -  Time elapsed: 0m54s\n",
            "    [15104-15360]  -  Average loss: 0.093  -  Time elapsed: 0m54s\n",
            "    [15360-15616]  -  Average loss: 0.094  -  Time elapsed: 0m55s\n",
            "    [15616-15872]  -  Average loss: 0.093  -  Time elapsed: 0m55s\n",
            "    [15872-16128]  -  Average loss: 0.091  -  Time elapsed: 0m53s\n",
            "    [16128-16384]  -  Average loss: 0.092  -  Time elapsed: 0m55s\n",
            "    [16384-16640]  -  Average loss: 0.094  -  Time elapsed: 0m55s\n",
            "    [16640-16896]  -  Average loss: 0.094  -  Time elapsed: 0m56s\n",
            "    [16896-17152]  -  Average loss: 0.093  -  Time elapsed: 0m54s\n",
            "    [17152-17408]  -  Average loss: 0.092  -  Time elapsed: 0m55s\n",
            "    [17408-17664]  -  Average loss: 0.090  -  Time elapsed: 0m54s\n",
            "    [17664-17920]  -  Average loss: 0.090  -  Time elapsed: 0m54s\n",
            "    [17920-18176]  -  Average loss: 0.094  -  Time elapsed: 0m55s\n",
            "    [18176-18432]  -  Average loss: 0.093  -  Time elapsed: 0m54s\n",
            "    [18432-18688]  -  Average loss: 0.094  -  Time elapsed: 0m53s\n",
            "    [18688-18944]  -  Average loss: 0.093  -  Time elapsed: 0m55s\n",
            "    [18944-19200]  -  Average loss: 0.090  -  Time elapsed: 0m54s\n",
            "    [19200-19456]  -  Average loss: 0.091  -  Time elapsed: 0m55s\n",
            "    [19456-19712]  -  Average loss: 0.093  -  Time elapsed: 0m54s\n",
            "    [19712-19968]  -  Average loss: 0.093  -  Time elapsed: 0m54s\n",
            "    [19968-20224]  -  Average loss: 0.090  -  Time elapsed: 0m54s\n",
            "    [20224-20480]  -  Average loss: 0.093  -  Time elapsed: 0m54s\n",
            "    [20480-20736]  -  Average loss: 0.095  -  Time elapsed: 0m52s\n",
            "    [20736-20992]  -  Average loss: 0.092  -  Time elapsed: 0m55s\n",
            "    [20992-21248]  -  Average loss: 0.091  -  Time elapsed: 0m54s\n",
            "    [21248-21504]  -  Average loss: 0.094  -  Time elapsed: 0m55s\n",
            "    [21504-21760]  -  Average loss: 0.094  -  Time elapsed: 0m54s\n",
            "    [21760-22016]  -  Average loss: 0.092  -  Time elapsed: 0m55s\n",
            "    [22016-22272]  -  Average loss: 0.090  -  Time elapsed: 0m53s\n",
            "    [22272-22528]  -  Average loss: 0.091  -  Time elapsed: 0m55s\n",
            "    [22528-22784]  -  Average loss: 0.094  -  Time elapsed: 0m55s\n",
            "    [22784-23040]  -  Average loss: 0.091  -  Time elapsed: 0m55s\n",
            "    [23040-23296]  -  Average loss: 0.091  -  Time elapsed: 0m54s\n",
            "    [23296-23552]  -  Average loss: 0.092  -  Time elapsed: 0m53s\n",
            "\u001b[94m-----  Ended Train Epoch ---- Start of validation metrics computation  -----\n",
            "\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10b1bfceddd2488db5ea3f3e939b7316",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "0it [00:00, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "====================================================================================================\n",
            "Training log:\n",
            "- Epoch: 3/10\n",
            "- Train loss: 0.09285647877842206\n",
            "- Val Top-1 Accuracy: 0.12408759124087591\n",
            "- Val Top-1 F1 Score: 0.3049154211562971\n",
            "- Val Top-K Accuracy: 0.20301094890510948\n",
            "- Val Top-K F1 Score: 0.4312051047087544\n",
            "====================================================================================================\n",
            "\n",
            "\n",
            "====================================================================================================\n",
            "Saved checkpoint to \"checkpoint_small.pth\".\n",
            "Best top 5 F1-score value:  0.4312051047087544\n",
            "====================================================================================================\n",
            "\n",
            "> EPOCH 4\n",
            "    [0-256]  -  Average loss: 0.084  -  Time elapsed: 0m58s\n",
            "    [256-512]  -  Average loss: 0.083  -  Time elapsed: 0m55s\n",
            "    [512-768]  -  Average loss: 0.084  -  Time elapsed: 0m55s\n",
            "    [768-1024]  -  Average loss: 0.085  -  Time elapsed: 0m54s\n",
            "    [1024-1280]  -  Average loss: 0.085  -  Time elapsed: 0m54s\n",
            "    [1280-1536]  -  Average loss: 0.083  -  Time elapsed: 0m55s\n",
            "    [1536-1792]  -  Average loss: 0.083  -  Time elapsed: 0m54s\n",
            "    [1792-2048]  -  Average loss: 0.083  -  Time elapsed: 0m54s\n",
            "    [2048-2304]  -  Average loss: 0.085  -  Time elapsed: 0m56s\n",
            "    [2304-2560]  -  Average loss: 0.085  -  Time elapsed: 0m55s\n",
            "    [2560-2816]  -  Average loss: 0.085  -  Time elapsed: 0m54s\n",
            "    [2816-3072]  -  Average loss: 0.086  -  Time elapsed: 0m53s\n",
            "    [3072-3328]  -  Average loss: 0.085  -  Time elapsed: 0m53s\n",
            "    [3328-3584]  -  Average loss: 0.085  -  Time elapsed: 0m54s\n",
            "    [3584-3840]  -  Average loss: 0.083  -  Time elapsed: 0m55s\n",
            "    [3840-4096]  -  Average loss: 0.085  -  Time elapsed: 0m54s\n",
            "    [4096-4352]  -  Average loss: 0.083  -  Time elapsed: 0m55s\n",
            "    [4352-4608]  -  Average loss: 0.086  -  Time elapsed: 0m53s\n",
            "    [4608-4864]  -  Average loss: 0.084  -  Time elapsed: 0m55s\n",
            "    [4864-5120]  -  Average loss: 0.086  -  Time elapsed: 0m53s\n"
          ]
        }
      ],
      "source": [
        "#model.load_state_dict(torch.load(\"/content/drive/MyDrive/Sourcery/codeBERTa.pt\"))\n",
        "train_and_validate(model, train_dataloader,val_dataloader,device=device, config=config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUVMKaz60NUb"
      },
      "outputs": [],
      "source": [
        "import dill"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VDqHzbL8z8hN"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/OriginalFullDatasetState', pickle_module=dill)\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/OriginalFullDatasetState')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDoBTXKlmS8c"
      },
      "source": [
        "## Quantization\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgrsHE9dIWMe"
      },
      "outputs": [],
      "source": [
        "# import dill\n",
        "\n",
        "# # torch.save(model, '/Quantization', pickle_module=dill)\n",
        "\n",
        "# model = torch.load('drive/MyDrive/codenet_data/OriginalModel', map_location=torch.device('cpu'), pickle_module=dill)\n",
        "# model = torch.quantization.quantize_dynamic(\n",
        "#     model, {torch.nn.Linear}, dtype=torch.qint8\n",
        "# )\n",
        "\n",
        "# val_top1_acc,val_top1_f1,val_topK_acc,val_topK_f1 = evaluate_full_dataset(val_dataloader,model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hf6rfhkEIUV9"
      },
      "outputs": [],
      "source": [
        "from numpy import array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IuDJC6dzKnuI"
      },
      "outputs": [],
      "source": [
        "#Small test on single eval batch\n",
        "start_time = time()\n",
        "val_dataloader.create_batches()\n",
        "for batch in tqdm(val_dataloader.batches):\n",
        "    topk_sequence,topk_length,tgt_seqs,tgt_lens,output_prob,decoded_sequences,inputs_raw = model.evaluate(batch)\n",
        "    decoded_labels = model.tokenizer.batch_decode(tgt_seqs,skip_special_tokens=False)\n",
        "    for i in range(len(decoded_sequences)):\n",
        "        print(i)\n",
        "        print(\"Input\")\n",
        "        print(inputs_raw[i])\n",
        "        print(i)\n",
        "        print(\"Decoded Sequences:\")\n",
        "        print(decoded_sequences[i])\n",
        "        print(i)\n",
        "        print(\"Decoded Labels:\")\n",
        "        print(decoded_labels[i])\n",
        "    break\n",
        "\n",
        "print(time() - start_time)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YBjAIHmC-bi"
      },
      "outputs": [],
      "source": [
        "# files.download('/content/checkpoint_small.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BE1N46CJmZ7l"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "CodeBERTa_model.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "04d848d79fad48618b89a5010bd2246b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a98e6674a184c31b006f08fbb576ff1",
            "placeholder": "​",
            "style": "IPY_MODEL_85278066a4304eaea74683590d9b4ec8",
            "value": " 483k/483k [00:00&lt;00:00, 621kB/s]"
          }
        },
        "05b8800f24054caaae891542c5f22585": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f3c7ab2d014a259efe07646edca45c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bd25d26c0c94a96957fe5f313521a79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c609e3d558e4de0896282e75a577685": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae8792d73bde4b00a63bcf120cb96c84",
            "placeholder": "​",
            "style": "IPY_MODEL_857db07640264b81acb094b6729b7a94",
            "value": "Downloading: 100%"
          }
        },
        "0cd53a624a814029b0b57321bab52e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3157e9cc2bd4ea2b900cf7d452b287d",
            "max": 336407488,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42bdc541d56e495da3b81c115209d91c",
            "value": 336407488
          }
        },
        "0d7a9b57eb5949d885a536fa12b321a4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dc7ce8e6b9b4c788b14fb29fe9d94aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0f39fd6ff9664302b2433dbf1707c58d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6246da18dd694546957fe889b3c9586c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_deb0f915186b4d58ad79d11b63719141",
            "value": 1
          }
        },
        "1079edb3494a480a9c1046415db837a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18f042dbf9cb46eab10b02e4dbd0eecc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a45abea31d644a9a8308ddb272c5bcc",
              "IPY_MODEL_d4659529995a4df3b7c85650b1bd43f5",
              "IPY_MODEL_f87bc7cc49fc4004a3d83e4bb1fb3bb1"
            ],
            "layout": "IPY_MODEL_43a8ed84a3b14dc9ada9e75f13e42fe7"
          }
        },
        "1a98e6674a184c31b006f08fbb576ff1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dca93ead0524d7db3958c16a8fac456": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_982d923c0c8749298a9de01f50d1e98f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ec714aa6b0c45dd96827f7a364f76dd",
            "value": 1
          }
        },
        "1e0b9fc47585474d830d3da11be1cf35": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58af2eacd6544d4a861e91b6fafe93d9",
              "IPY_MODEL_8f887822833a4f81bb94ac4f79b7e3f0",
              "IPY_MODEL_a754205486ee4bae9daa76b109c2b5ed"
            ],
            "layout": "IPY_MODEL_5786d874cf364649b516f3ae7ef8ea86"
          }
        },
        "1e319f38a55f4faeaa8dd80917d85a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ec7bdea25f140f8b97913a114fb6e93": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21edd439c0964a9cb9e0d18430b4e12d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e8394c9cd84d65beaddffeb3815797": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26696ae9e3ae4e3c9e9df0466043f634": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29913220601d4f1c917dd08a00ef2ab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55a260476d9a410a83af815ad63213da",
            "placeholder": "​",
            "style": "IPY_MODEL_d63c537eccd540b7b52794219d2e6f77",
            "value": ""
          }
        },
        "2a3cafa4b3fe4a06897f9055df115f42": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b52ba8f80d844a3b0ef9f2cc92d553f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cbdc33d3d6f4d0ea0a44b4c5ba8544b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a3cafa4b3fe4a06897f9055df115f42",
            "placeholder": "​",
            "style": "IPY_MODEL_9a543477a4d848e99fc1d39d7a6f7603",
            "value": "Downloading: 100%"
          }
        },
        "33880c7b95234e8280572f2751d7bfcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33b3099dfc8c4ddf92266e60752f421b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3492e382c3334c168768b275ecbb374a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b85fe4575bb4969b9e296745b587520": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "407ad57804334f11b1af75d5c024d6c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42bdc541d56e495da3b81c115209d91c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "43a8ed84a3b14dc9ada9e75f13e42fe7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "444cefde81bc4dff90664aee5f18b6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf664f7decff4a389c6a0046ce940506",
            "max": 993805,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0dc7ce8e6b9b4c788b14fb29fe9d94aa",
            "value": 993805
          }
        },
        "492a0e8183364ea4be0610214128d1f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a45abea31d644a9a8308ddb272c5bcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21edd439c0964a9cb9e0d18430b4e12d",
            "placeholder": "​",
            "style": "IPY_MODEL_492a0e8183364ea4be0610214128d1f4",
            "value": "Downloading: 100%"
          }
        },
        "535c78db3a654ad48646d3d8a08950fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "555f8f3ce59b4f9ba0489ab140a69c0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55a260476d9a410a83af815ad63213da": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55e10b21892540df85a94e069b719fd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56f3ee334db54236a4423156945d7ea6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5786d874cf364649b516f3ae7ef8ea86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58af2eacd6544d4a861e91b6fafe93d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9636154248fd404d9f6d44946dc36f16",
            "placeholder": "​",
            "style": "IPY_MODEL_ba22f546e10942e98ae4595d89877cfd",
            "value": "Downloading: 100%"
          }
        },
        "5cf15ff374044ca3849809e1b712f8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33880c7b95234e8280572f2751d7bfcf",
            "placeholder": "​",
            "style": "IPY_MODEL_407ad57804334f11b1af75d5c024d6c7",
            "value": " 137/? [00:47&lt;00:00,  3.18it/s]"
          }
        },
        "606e974774bf491faa80f0594a31f891": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6246da18dd694546957fe889b3c9586c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "624def337fc04dcf9ebb118331fbe0b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "69e045e677ef4862a8bb321b0e6c9e9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ec714aa6b0c45dd96827f7a364f76dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f4b40e3ad1c4aa4bd0c2f6a794e43fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ba800be5d954261970a31c6ce294b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b85fe4575bb4969b9e296745b587520",
            "placeholder": "​",
            "style": "IPY_MODEL_69e045e677ef4862a8bb321b0e6c9e9c",
            "value": "Downloading: 100%"
          }
        },
        "80b0a05094eb4523a785482a7e1c8d0f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85278066a4304eaea74683590d9b4ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "857db07640264b81acb094b6729b7a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f887822833a4f81bb94ac4f79b7e3f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d7a9b57eb5949d885a536fa12b321a4",
            "max": 480,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b52ba8f80d844a3b0ef9f2cc92d553f",
            "value": 480
          }
        },
        "9308302ef94c4d1f942ef35e17aaf35f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94700731c6ff4bcaaf5e6583d79a5e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c609e3d558e4de0896282e75a577685",
              "IPY_MODEL_0cd53a624a814029b0b57321bab52e25",
              "IPY_MODEL_f055bc5b9d6148ed9652727b9d9d7ff1"
            ],
            "layout": "IPY_MODEL_9e44c8fa5cbe4625bd9673ea4ffe420a"
          }
        },
        "9636154248fd404d9f6d44946dc36f16": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "965f64f465b642118e59bc8e38bc2258": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ec7bdea25f140f8b97913a114fb6e93",
            "placeholder": "​",
            "style": "IPY_MODEL_55e10b21892540df85a94e069b719fd6",
            "value": ""
          }
        },
        "96acb4b8c3484ea18e68e100cc691cf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "982d923c0c8749298a9de01f50d1e98f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "996a44f0fcc74aa591a7dac4662d8079": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_29913220601d4f1c917dd08a00ef2ab8",
              "IPY_MODEL_1dca93ead0524d7db3958c16a8fac456",
              "IPY_MODEL_dc54c049a6504bf48a64f791a68107a3"
            ],
            "layout": "IPY_MODEL_1079edb3494a480a9c1046415db837a0"
          }
        },
        "9a543477a4d848e99fc1d39d7a6f7603": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e44c8fa5cbe4625bd9673ea4ffe420a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a754205486ee4bae9daa76b109c2b5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d05ffede87924863a09e29090b012dae",
            "placeholder": "​",
            "style": "IPY_MODEL_26696ae9e3ae4e3c9e9df0466043f634",
            "value": " 480/480 [00:00&lt;00:00, 11.4kB/s]"
          }
        },
        "ae8792d73bde4b00a63bcf120cb96c84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b21867dd30ea44218d714198cc60c99e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9308302ef94c4d1f942ef35e17aaf35f",
            "placeholder": "​",
            "style": "IPY_MODEL_ca15aff3664a4f3ebaf69e9ab20190c2",
            "value": " 994k/994k [00:00&lt;00:00, 2.07MB/s]"
          }
        },
        "b7e6edec8ce8467391fc5c87dde7f072": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ba08760c15374a11bf8e355d4a368d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0740d5e3a2f463cad3d923a852e0f7b",
            "placeholder": "​",
            "style": "IPY_MODEL_606e974774bf491faa80f0594a31f891",
            "value": ""
          }
        },
        "ba22f546e10942e98ae4595d89877cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be97a599ff99428fbbf27fde889e2352": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80b0a05094eb4523a785482a7e1c8d0f",
            "placeholder": "​",
            "style": "IPY_MODEL_0bd25d26c0c94a96957fe5f313521a79",
            "value": " 137/? [00:36&lt;00:00,  3.65it/s]"
          }
        },
        "c0fdb566540842a799f876bdb0d76685": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c21a6902b3d44c6bb9e66b3dc6e44bfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_965f64f465b642118e59bc8e38bc2258",
              "IPY_MODEL_0f39fd6ff9664302b2433dbf1707c58d",
              "IPY_MODEL_be97a599ff99428fbbf27fde889e2352"
            ],
            "layout": "IPY_MODEL_3492e382c3334c168768b275ecbb374a"
          }
        },
        "c3157e9cc2bd4ea2b900cf7d452b287d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca15aff3664a4f3ebaf69e9ab20190c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf664f7decff4a389c6a0046ce940506": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d05ffede87924863a09e29090b012dae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0740d5e3a2f463cad3d923a852e0f7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d144a772d7e346c9934807029f6bd53e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2cbdc33d3d6f4d0ea0a44b4c5ba8544b",
              "IPY_MODEL_e0c34133ecc04a3e8a8b721917ae234f",
              "IPY_MODEL_04d848d79fad48618b89a5010bd2246b"
            ],
            "layout": "IPY_MODEL_b7e6edec8ce8467391fc5c87dde7f072"
          }
        },
        "d4659529995a4df3b7c85650b1bd43f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_535c78db3a654ad48646d3d8a08950fc",
            "max": 19,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e319f38a55f4faeaa8dd80917d85a02",
            "value": 19
          }
        },
        "d48fb7371e344b639065c4eecbdc3f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ba08760c15374a11bf8e355d4a368d6e",
              "IPY_MODEL_dc93b2c2e8b241abb64738112c67daa8",
              "IPY_MODEL_5cf15ff374044ca3849809e1b712f8a6"
            ],
            "layout": "IPY_MODEL_05b8800f24054caaae891542c5f22585"
          }
        },
        "d63c537eccd540b7b52794219d2e6f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dc54c049a6504bf48a64f791a68107a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33b3099dfc8c4ddf92266e60752f421b",
            "placeholder": "​",
            "style": "IPY_MODEL_56f3ee334db54236a4423156945d7ea6",
            "value": " 137/? [00:42&lt;00:00,  3.82it/s]"
          }
        },
        "dc93b2c2e8b241abb64738112c67daa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96acb4b8c3484ea18e68e100cc691cf5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c0fdb566540842a799f876bdb0d76685",
            "value": 1
          }
        },
        "deb0f915186b4d58ad79d11b63719141": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e0c34133ecc04a3e8a8b721917ae234f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25e8394c9cd84d65beaddffeb3815797",
            "max": 482532,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fa1366f583e342328aa1a5b180bbe430",
            "value": 482532
          }
        },
        "ec7ee1ef18b44b07b50e158a8adbe7ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ba800be5d954261970a31c6ce294b69",
              "IPY_MODEL_444cefde81bc4dff90664aee5f18b6af",
              "IPY_MODEL_b21867dd30ea44218d714198cc60c99e"
            ],
            "layout": "IPY_MODEL_6f4b40e3ad1c4aa4bd0c2f6a794e43fc"
          }
        },
        "f055bc5b9d6148ed9652727b9d9d7ff1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07f3c7ab2d014a259efe07646edca45c",
            "placeholder": "​",
            "style": "IPY_MODEL_555f8f3ce59b4f9ba0489ab140a69c0c",
            "value": " 336M/336M [00:09&lt;00:00, 36.8MB/s]"
          }
        },
        "f12368dbdace4b4da562346e4bb50bf5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f87bc7cc49fc4004a3d83e4bb1fb3bb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f12368dbdace4b4da562346e4bb50bf5",
            "placeholder": "​",
            "style": "IPY_MODEL_624def337fc04dcf9ebb118331fbe0b7",
            "value": " 19.0/19.0 [00:00&lt;00:00, 625B/s]"
          }
        },
        "fa1366f583e342328aa1a5b180bbe430": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}